{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from transformers import *\n",
    "from kaiser.src import utils\n",
    "from kaiser.src import dataio\n",
    "from kaiser.src.modeling import BertForJointShallowSemanticParsing, FrameBERT\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from kaiser.src.prototypical_loss import prototypical_loss as loss_fn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from kaiser.src.prototypical_loss import prototypical_loss as loss_fn\n",
    "from kaiser.src import prototypical_batch_sampler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(0)\n",
    "# device = torch.device('cpu')\n",
    "# torch.cuda.set_device(device)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(0)   \n",
    "random.seed(0)\n",
    "import random\n",
    "\n",
    "from torch import autograd\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    }
   ],
   "source": [
    "bert_io = utils.for_BERT(mode='train', language='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrameBERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameBERT_dir = '/disk/data/models/frameBERT/frameBERT_en'\n",
    "\n",
    "frameBERT = FrameBERT.from_pretrained(frameBERT_dir,\n",
    "                                      num_senses = len(bert_io.sense2idx), \n",
    "                                      num_args = len(bert_io.bio_arg2idx),\n",
    "                                      lufrmap=bert_io.lufrmap, \n",
    "                                      frargmap = bert_io.bio_frargmap)\n",
    "frameBERT.to(device)\n",
    "frameBERT.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading FN data\n",
      "# of instances in trn: 19391\n",
      "# of instances in dev: 2272\n",
      "# of instances in tst: 6714\n",
      "data example: [['Greece', 'wildfires', 'force', 'thousands', 'to', '<tgt>', 'evacuate', '</tgt>'], ['_', '_', '_', '_', '_', '_', 'evacuate.v', '_'], ['_', '_', '_', '_', '_', '_', 'Escaping', '_'], ['O', 'O', 'O', 'B-Escapee', 'O', 'X', 'O', 'X']]\n",
      "... converting FN data to BERT\n",
      "0hour:0min:9sec\n"
     ]
    }
   ],
   "source": [
    "print('... loading FN data')\n",
    "tic()\n",
    "trn, dev, tst = dataio.load_data(srl='framenet', language='en', exem=True)\n",
    "# trn = random.sample(trn, k=500)\n",
    "# dev = random.sample(trn, k=100)\n",
    "# tst = random.sample(tst, k=100)\n",
    "print('... converting FN data to BERT')\n",
    "trn_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(trn)\n",
    "dev_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(dev)\n",
    "tst_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(tst)\n",
    "\n",
    "with open('./koreanframenet/resource/info/fn1.7_frame2idx.json', 'r') as f:\n",
    "    frame2idx = json.load(f)\n",
    "with open('./koreanframenet/resource/info/fn1.7_frame_definitions.json', 'r') as f:\n",
    "    frame2definition = json.load(f)\n",
    "\n",
    "def_data, def_y = bert_io.convert_to_bert_input_label_definition(frame2definition, frame2idx)\n",
    "print(tac())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_target_frames: 89\n",
      "dev_target_frames: 13\n",
      "tst_target_frames: 17\n"
     ]
    }
   ],
   "source": [
    "def save_list_to_file(path, thelist):\n",
    "    with open(path, 'w') as f:\n",
    "        for item in thelist:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "def get_y(data):\n",
    "    with open('./koreanframenet/resource/info/fn1.7_frame2idx.json', 'r') as f:\n",
    "        frame2idx = json.load(f)\n",
    "    y = []\n",
    "    for instance in data:\n",
    "        frame = False\n",
    "        for i in instance[2]:\n",
    "            if i != '_':\n",
    "                frame = i\n",
    "                break\n",
    "        frameidx = frame2idx[frame]\n",
    "        y.append(frameidx)\n",
    "    return tuple(y)\n",
    "\n",
    "def get_target_frames(input_data):\n",
    "    all_y = dict(Counter(get_y(input_data)))\n",
    "    target_frames = []\n",
    "    for i in all_y:\n",
    "        count = all_y[i]\n",
    "        if count >= 5:\n",
    "            target_frames.append(i)\n",
    "            \n",
    "    return target_frames\n",
    "            \n",
    "trn_target_frames = get_target_frames(trn)\n",
    "dev_target_frames = get_target_frames(dev)\n",
    "tst_target_frames = get_target_frames(tst)\n",
    "\n",
    "print('trn_target_frames:', len(trn_target_frames))\n",
    "print('dev_target_frames:', len(dev_target_frames))\n",
    "print('tst_target_frames:', len(tst_target_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    }
   ],
   "source": [
    "trn_batch_sampler = prototypical_batch_sampler.PrototypicalBatchSampler(classes_per_it=60, \n",
    "                                                                        num_support=5,\n",
    "                                                                        target_frames=trn_target_frames, \n",
    "                                                                        def_data=def_data, def_y=def_y)\n",
    "\n",
    "# trn_batch_sampler = prototypical_batch_sampler.PrototypicalBatchSampler(classes_per_it=4, \n",
    "#                                                                         num_support=2,\n",
    "#                                                                         target_frames=trn_target_frames, \n",
    "#                                                                         def_data=def_data, def_y=def_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    }
   ],
   "source": [
    "dev_batch_sampler = prototypical_batch_sampler.PrototypicalBatchSampler(classes_per_it=5, \n",
    "                                                                        num_support=5, \n",
    "                                                                        target_frames=dev_target_frames, \n",
    "                                                                        def_data=def_data, def_y=def_y)\n",
    "\n",
    "# dev_batch_sampler = prototypical_batch_sampler.PrototypicalBatchSampler(classes_per_it=4, \n",
    "#                                                                         num_support=2, \n",
    "#                                                                         target_frames=dev_target_frames, \n",
    "#                                                                         def_data=def_data, def_y=def_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    }
   ],
   "source": [
    "tst_batch_sampler = prototypical_batch_sampler.PrototypicalBatchSampler(classes_per_it=5, \n",
    "                                                                        num_support=5, \n",
    "                                                                        target_frames=tst_target_frames, \n",
    "                                                                        def_data=def_data, def_y=def_y)\n",
    "\n",
    "# tst_batch_sampler = prototypical_batch_sampler.PrototypicalBatchSampler(classes_per_it=4, \n",
    "#                                                                         num_support=2, \n",
    "#                                                                         target_frames=tst_target_frames, \n",
    "#                                                                         def_data=def_data, def_y=def_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs_from_episode(episode):\n",
    "    support_embs = []\n",
    "    query_embs = []\n",
    "    \n",
    "    support_y, query_y = [],[]\n",
    "    \n",
    "    for class_indice in episode:\n",
    "        support_examples, query_examples = class_indice\n",
    "\n",
    "        query_inputs, _, query_token_type_ids, query_masks = query_examples[0][0]\n",
    "        query_inputs = query_inputs.view(1,len(query_inputs)).to(device)\n",
    "        query_token_type_ids = query_token_type_ids.view(1,len(query_token_type_ids)).to(device)\n",
    "        query_masks = query_masks.view(1,len(query_masks)).to(device)\n",
    "        \n",
    "        query_frame = query_examples[0][1]\n",
    "        query_y.append(query_frame)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            _, query_emb = frameBERT(query_inputs, \n",
    "                                  token_type_ids=query_token_type_ids, \n",
    "                                  attention_mask=query_masks)\n",
    "            query_emb = query_emb.view(-1)\n",
    "        query_embs.append(query_emb)\n",
    "        \n",
    "        support_inputs, support_token_type_ids, support_masks = [],[],[]\n",
    "        for i in range(len(support_examples)):\n",
    "            support_input, _, _, _, _, support_token_type_id, support_mask = support_examples[i][0]\n",
    "            support_inputs.append(support_input)\n",
    "            support_token_type_ids.append(support_token_type_id)\n",
    "            support_masks.append(support_mask)\n",
    "            \n",
    "            support_frame = support_examples[i][1]\n",
    "            support_y.append(support_frame)\n",
    "            \n",
    "        support_inputs = torch.stack(support_inputs).to(device)\n",
    "        support_token_type_ids = torch.stack(support_token_type_ids).to(device)\n",
    "        support_masks = torch.stack(support_masks).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, support_emb = frameBERT(support_inputs, \n",
    "                                  token_type_ids=support_token_type_ids, \n",
    "                                  attention_mask=support_masks)\n",
    "        support_embs.append(support_emb)\n",
    "        \n",
    "    support_embs = torch.stack(support_embs)\n",
    "    support_embs = support_embs.view(-1, 768)\n",
    "    query_embs = torch.stack(query_embs)\n",
    "    \n",
    "    support_y = tuple(support_y)\n",
    "    query_y = tuple(query_y)\n",
    "    \n",
    "    return support_embs, query_embs, support_y, query_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trn_batch, dev_batch,  best_model_path, last_model_path, model=False):\n",
    "    # load optimizer\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.classifier.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "    optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "    max_grad_norm = 1.0\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(TRN_EPOCHS):\n",
    "        model.train()\n",
    "        for episode in trn_batch:\n",
    "            support_embs, query_embs, support_y, query_y = get_embs_from_episode(episode)\n",
    "            \n",
    "            support_embs = model(support_embs)\n",
    "            query_embs = model(query_embs)\n",
    "\n",
    "            loss, acc = loss_fn(support_embs, query_embs, support_y, query_y, len(support_y))\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(acc.item())\n",
    "\n",
    "            \n",
    "        avg_loss = np.mean(train_loss[-100:])\n",
    "        avg_acc = np.mean(train_acc[-100:])\n",
    "        print('Avg Train Loss: {}, Avg Train Acc: {}'.format(avg_loss, avg_acc))\n",
    "        \n",
    "        model.eval()\n",
    "        for episode in dev_batch:\n",
    "            support_embs, query_embs, support_y, query_y = get_embs_from_episode(episode)\n",
    "            support_embs = model(support_embs)\n",
    "            query_embs = model(query_embs)\n",
    "            \n",
    "            loss_val, acc_val = loss_fn(support_embs, query_embs, support_y, query_y, len(support_y))\n",
    "            \n",
    "            val_loss.append(loss_val.item())\n",
    "            val_acc.append(acc_val.item())\n",
    "\n",
    "            \n",
    "        avg_loss = np.mean(val_loss[-100:])\n",
    "        avg_acc = np.mean(val_acc[-100:])\n",
    "        \n",
    "        postfix = ' (Best)' if avg_acc >= best_acc else ' (Best: {})'.format(\n",
    "            best_acc)\n",
    "        print('Avg Val Loss: {}, Avg Val Acc: {}{}'.format(\n",
    "            avg_loss, avg_acc, postfix))\n",
    "        \n",
    "        if avg_acc >= best_acc:\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            best_acc = avg_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    torch.save(model.state_dict(), last_model_path)\n",
    "\n",
    "    for name in ['train_loss', 'train_acc', 'val_loss', 'val_acc']:\n",
    "        save_list_to_file(os.path.join('/disk/data/models/framenet/prototype_mlp/',\n",
    "                                       name + '.txt'), locals()[name])\n",
    "        \n",
    "        \n",
    "        \n",
    "# best_model_path = '/disk/data/models/framenet/prototype_mlp/best_model.pth'\n",
    "# last_model_path = '/disk/data/models/framenet/prototype_mlp/last_model.pth'\n",
    "# trn_y = get_y(trn)\n",
    "# dev_y = get_y(dev)\n",
    "\n",
    "# trn_batch = trn_batch_sampler.gen_batch(trn_data, trn_y)\n",
    "# dev_batch = dev_batch_sampler.gen_batch(dev_data, dev_y)\n",
    "\n",
    "# TRN_EPOCHS = 100\n",
    "# mlp_model = MLP()\n",
    "# mlp_model.to(device)\n",
    "\n",
    "# print('\\n...training')\n",
    "# train(trn_batch, dev_batch, best_model_path, last_model_path, model=mlp_model)\n",
    "# print(tac())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tst_batch, model_path=False):\n",
    "    avg_acc = list()\n",
    "    model = MLP()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    for epoch in range(10):\n",
    "        model.eval()\n",
    "        for episode in tst_batch:\n",
    "            support_embs, query_embs, support_y, query_y = get_embs_from_episode(episode)\n",
    "\n",
    "            support_embs = model(support_embs)\n",
    "            query_embs = model(query_embs)\n",
    "\n",
    "            _, acc_val = loss_fn(support_embs, query_embs, support_y, query_y, len(support_y))\n",
    "\n",
    "            avg_acc.append(acc_val.item())\n",
    "        \n",
    "    avg_acc = np.mean(avg_acc)\n",
    "    print('Test Acc: {}'.format(avg_acc))\n",
    "    with open('/disk/data/models/framenet/prototype_mlp/test_acc.txt','w') as f:\n",
    "        f.write(str(avg_acc))\n",
    "        \n",
    "best_model_path = '/disk/data/models/framenet/prototype_mlp/best_model.pth'\n",
    "tst_y = get_y(tst)\n",
    "tst_batch = tst_batch_sampler.gen_batch(tst_data, tst_y)\n",
    "\n",
    "\n",
    "print('\\n...testing')\n",
    "test(tst_batch, model_path=best_model_path)\n",
    "print(tac())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
