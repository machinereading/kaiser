{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1120 21:19:38.706986 140133130520320 file_utils.py:39] PyTorch version 0.4.1 available.\n",
      "I1120 21:19:38.930562 140133130520320 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import *\n",
    "from kaiser.src import utils\n",
    "from kaiser.src import dataio\n",
    "from kaiser import target_identifier\n",
    "from kaiser import inference\n",
    "from kaiser.src.modeling import BertForJointShallowSemanticParsing\n",
    "from kaiser.koreanframenet.src import conll2textae\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "print('\\n\\t###DEVICE:', device)\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowSemanticParser():\n",
    "    def __init__(self, fnversion=1.1, language='ko',masking=True, srl='framenet', \n",
    "                 model_path=False, gold_pred=False, viterbi=False, tgt=True, \n",
    "                 pretrained='bert-base-multilingual-cased'):\n",
    "        self.fnversion = fnversion\n",
    "        self.language = language\n",
    "        self.masking = masking\n",
    "        self.srl = srl\n",
    "        self.gold_pred = gold_pred\n",
    "        self.viterbi = viterbi\n",
    "        self.pretrained = pretrained\n",
    "        self.tgt = tgt #using <tgt> and </tgt> as a special token\n",
    "        \n",
    "        if self.masking==True:\n",
    "            self.targetid = target_identifier.targetIdentifier()\n",
    "        else:\n",
    "            self.targetid = target_identifier.targetIdentifier(only_lu=False)\n",
    "            \n",
    "        if self.srl == 'propbank-dp':\n",
    "            self.viterbi = False\n",
    "            self.masking = False\n",
    "        \n",
    "        print('srl model:', self.srl)\n",
    "        print('language:', self.language)\n",
    "        print('version:', self.fnversion)\n",
    "        print('using viterbi:', self.viterbi)\n",
    "        print('using masking:', self.masking)\n",
    "        print('pretrained BERT:', self.pretrained)\n",
    "        print('using TGT special token:', self.tgt)\n",
    "        \n",
    "        self.bert_io = utils.for_BERT(mode='predict', srl=self.srl, language=self.language, \n",
    "                              masking=self.masking, fnversion=self.fnversion,\n",
    "                              pretrained=self.pretrained)  \n",
    "        \n",
    "        #load model\n",
    "        if model_path:\n",
    "            self.model_path = model_path\n",
    "        else:\n",
    "            print('model_path={your_model_dir}')\n",
    "#         self.model = torch.load(model_path, map_location=device)\n",
    "\n",
    "        self.model = BertForJointShallowSemanticParsing.from_pretrained(self.model_path, \n",
    "                                                                   num_senses = len(self.bert_io.sense2idx), \n",
    "                                                                   num_args = len(self.bert_io.bio_arg2idx),\n",
    "                                                                   lufrmap=self.bert_io.lufrmap, \n",
    "                                                                   frargmap = self.bert_io.bio_frargmap)\n",
    "        self.model.to(device)\n",
    "#         self.model = BertForJointShallowSemanticParsing\n",
    "        self.model.eval()\n",
    "        print(self.model_path)\n",
    "        print('...model is loaded')\n",
    "        \n",
    "        # trainsition parameter for vitervi decoding\n",
    "        if self.srl != 'propbank-dp':\n",
    "            self.transition_param = inference.get_transition_params(self.bert_io.idx2bio_arg.values())\n",
    "        \n",
    "    def parser(self, input_d, sent_id=False, result_format=False):\n",
    "        input_conll = dataio.preprocessor(input_d)\n",
    "        \n",
    "        #target identification\n",
    "        if self.gold_pred:\n",
    "            if len(input_conll[0]) == 2:\n",
    "                pass\n",
    "            else:\n",
    "                input_conll = [input_conll]\n",
    "            tgt_data = input_conll\n",
    "        else:\n",
    "            if self.srl == 'framenet':\n",
    "                tgt_conll = self.targetid.target_id(input_conll)\n",
    "            else:\n",
    "                tgt_conll = self.targetid.pred_id(input_conll)\n",
    "        \n",
    "            # add <tgt> and </tgt> to target word\n",
    "            tgt_data = dataio.data2tgt_data(tgt_conll, mode='parse')\n",
    "\n",
    "        if tgt_data:\n",
    "            \n",
    "            # convert conll to bert inputs\n",
    "            bert_inputs = self.bert_io.convert_to_bert_input_JointShallowSemanticParsing(tgt_data)\n",
    "            dataloader = DataLoader(bert_inputs, sampler=None, batch_size=6)\n",
    "            \n",
    "            pred_senses, pred_args = [],[]            \n",
    "            for batch in dataloader:\n",
    "                torch.cuda.set_device(device)\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_orig_tok_to_maps, b_lus, b_token_type_ids, b_masks = batch\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    tmp_eval_loss = self.model(b_input_ids, lus=b_lus, \n",
    "                                               token_type_ids=b_token_type_ids, attention_mask=b_masks)\n",
    "                    sense_logits, arg_logits = self.model(b_input_ids, lus=b_lus, \n",
    "                                                          token_type_ids=b_token_type_ids, attention_mask=b_masks)\n",
    "                \n",
    "                if self.srl == 'framenet':\n",
    "                    lufr_masks = utils.get_masks(b_lus, \n",
    "                                                 self.bert_io.lufrmap, \n",
    "                                                 num_label=len(self.bert_io.sense2idx), \n",
    "                                                 masking=self.masking).to(device)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                b_input_ids_np = b_input_ids.detach().cpu().numpy()\n",
    "                \n",
    "#                 sense_logits_np = sense_logits.detach().cpu().numpy()\n",
    "                arg_logits_np = arg_logits.detach().cpu().numpy()\n",
    "#                 arg_logits_np = arg_logits\n",
    "                \n",
    "                b_input_ids, arg_logits = [],[]\n",
    "                \n",
    "                for b_idx in range(len(b_orig_tok_to_maps)):\n",
    "                    orig_tok_to_map = b_orig_tok_to_maps[b_idx]\n",
    "                    bert_token = self.bert_io.tokenizer.convert_ids_to_tokens(b_input_ids_np[b_idx])\n",
    "                    tgt_idx = utils.get_tgt_idx(bert_token, tgt=self.tgt)                                      \n",
    "                    \n",
    "                    input_id, sense_logit, arg_logit = [],[],[]\n",
    "\n",
    "                    for idx in orig_tok_to_map:                        \n",
    "                        if idx != -1:\n",
    "                            if idx not in tgt_idx:\n",
    "                                input_id.append(b_input_ids_np[b_idx][idx])\n",
    "                                arg_logits_np[b_idx][idx][1] = np.NINF\n",
    "                                arg_logit.append(arg_logits_np[b_idx][idx])\n",
    "                            \n",
    "                    b_input_ids.append(input_id)\n",
    "                    arg_logits.append(arg_logit)\n",
    "                    \n",
    "                b_input_ids = torch.Tensor(b_input_ids).to(device)\n",
    "                arg_logits = torch.Tensor(arg_logits).to(device)\n",
    "    \n",
    "                for b_idx in range(len(sense_logits)):\n",
    "                    input_id = b_input_ids[b_idx]\n",
    "                    sense_logit = sense_logits[b_idx]\n",
    "#                     sense_logit = sense_logits_np[b_idx]\n",
    "                    arg_logit = arg_logits[b_idx]\n",
    "                    \n",
    "                    if self.srl == 'framenet':\n",
    "                        lufr_mask = lufr_masks[b_idx]                        \n",
    "                        masked_sense_logit = utils.masking_logit(sense_logit, lufr_mask)\n",
    "                        pred_sense, sense_score = utils.logit2label(masked_sense_logit)\n",
    "                    else:\n",
    "                        pred_sense, sense_score = utils.logit2label(sense_logit)\n",
    "                        \n",
    "                    orig_tok_to_map = b_orig_tok_to_maps[b_idx]\n",
    "                    \n",
    "                    if self.srl == 'framenet':\n",
    "                        arg_logit_np = arg_logit.detach().cpu().numpy()\n",
    "                        arg_logit = []\n",
    "                        frarg_mask = utils.get_masks([pred_sense], \n",
    "                                                     self.bert_io.bio_frargmap, \n",
    "                                                     num_label=len(self.bert_io.bio_arg2idx), \n",
    "                                                     masking=True).to(device)[0]\n",
    "                        for logit in arg_logit_np:\n",
    "                            masked_logit = utils.masking_logit(logit, frarg_mask)\n",
    "                            arg_logit.append(np.array(masked_logit))\n",
    "                        arg_logit = torch.Tensor(arg_logit).to(device)\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "                    if self.viterbi and len(arg_logit) > 1:\n",
    "                        sm = nn.Softmax(dim=1)\n",
    "                        arg_logit_softmax = sm(arg_logit)\n",
    "                        arg_logit = arg_logit.detach().cpu().numpy()\n",
    "                        pred_arg, _ = inference.viterbi_decode(arg_logit, self.transition_param)\n",
    "                    else:\n",
    "                        pred_arg = []\n",
    "                        for logit in arg_logit:\n",
    "                            label, score = utils.logit2label(logit)\n",
    "                            pred_arg.append(int(label))\n",
    "\n",
    "                    pred_senses.append([int(pred_sense)])\n",
    "                    pred_args.append(pred_arg)\n",
    "\n",
    "            pred_sense_tags = [self.bert_io.idx2sense[p_i] for p in pred_senses for p_i in p]\n",
    "\n",
    "            if self.srl == 'propbank-dp':\n",
    "                pred_arg_tags = [[self.bert_io.idx2arg[p_i] for p_i in p] for p in pred_args]\n",
    "            else:\n",
    "                pred_arg_tags = [[self.bert_io.idx2bio_arg[p_i] for p_i in p] for p in pred_args]\n",
    "\n",
    "            conll_result = []\n",
    "\n",
    "            for i in range(len(pred_arg_tags)):       \n",
    "                \n",
    "                raw = tgt_data[i]\n",
    "                \n",
    "                conll, toks, lus = [],[],[]\n",
    "                for idx in range(len(raw[0])):\n",
    "                    tok, lu = raw[0][idx], raw[1][idx]\n",
    "                    if tok == '<tgt>' or tok == '</tgt>':\n",
    "                        pass\n",
    "                    else:\n",
    "                        toks.append(tok)\n",
    "                        lus.append(lu)\n",
    "                conll.append(toks)\n",
    "                conll.append(lus)\n",
    "                \n",
    "                sense_seq = ['_' for i in range(len(conll[1]))]\n",
    "                for idx in range(len(conll[1])):\n",
    "                    if conll[1][idx] != '_':\n",
    "                        sense_seq[idx] = pred_sense_tags[i]\n",
    "                        \n",
    "                conll.append(sense_seq)\n",
    "                conll.append(pred_arg_tags[i])\n",
    "                \n",
    "                conll_result.append(conll)\n",
    "        else:\n",
    "            conll_result = []\n",
    "            \n",
    "            \n",
    "        if result_format == 'all':            \n",
    "            result = {}\n",
    "            result['conll'] = conll_result\n",
    "\n",
    "            if conll_result:\n",
    "                textae = conll2textae.get_textae(conll_result)\n",
    "                frdf = dataio.frame2rdf(conll_result, sent_id=sent_id)\n",
    "            else:\n",
    "                textae = []\n",
    "                frdf = []\n",
    "            result['textae'] = textae\n",
    "            result['graph'] = frdf\n",
    "        elif result_format == 'textae':\n",
    "            if conll_result:\n",
    "                textae = conll2textae.get_textae(conll_result)\n",
    "            else:\n",
    "                textae = []\n",
    "            result = textae\n",
    "        elif result_format == 'graph':\n",
    "            if conll_result:\n",
    "                frdf = dataio.frame2rdf(conll_result, sent_id=sent_id)\n",
    "            else:\n",
    "                frdf = []\n",
    "            result = frdf\n",
    "        else:\n",
    "            result = conll_result\n",
    "        \n",
    "        return result     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srl model: framenet\n",
      "language: ko\n",
      "using viterbi: True\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:218: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['그는', '그녀와', '사랑에', '빠졌다.']\n",
      "['_', '_', '사랑.n', '_']\n",
      "['B-Partner_1', 'O', 'O', 'B-Partner_2']\n",
      "\n",
      "['그는', '그녀와', '사랑에', '빠졌다.']\n",
      "['_', '_', '_', '빠지다.v']\n",
      "['B-Experiencer', 'B-Content', 'O', 'B-Topic']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_dir = '/disk/data/models/koframenet_1105/epoch-30-joint.pt'\n",
    "# s = Parser(gold_pred=False, model_dir=model_dir, viterbi=True)\n",
    "# # t = '헤밍웨이는 1899년 7월 21일 미국 일리노이에서 태어났고 62세에 자살로 사망했다.'\n",
    "# # t = '검은 얼룩이 흰 옷에서 빠졌다.'\n",
    "# t = '그는 그녀와 사랑에 빠졌다.'\n",
    "# d = s.shallowSemanticParser(t)\n",
    "# for i in d:\n",
    "#     for j in i:\n",
    "#         print(j)\n",
    "#     print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
