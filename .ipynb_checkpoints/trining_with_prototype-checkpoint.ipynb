{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from transformers import *\n",
    "from kaiser.src import utils\n",
    "from kaiser.src import dataio\n",
    "from kaiser.src.modeling import BertForJointShallowSemanticParsing, FrameBERT\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(0)\n",
    "# device = torch.device('cpu')\n",
    "# torch.cuda.set_device(device)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(0)   \n",
    "random.seed(0)\n",
    "import random\n",
    "\n",
    "from torch import autograd\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KD_loss = nn.KLDivLoss(reduction='batchmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    '''\n",
    "    Compute euclidean distance between two tensors\n",
    "    '''\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    if d != y.size(1):\n",
    "        raise Exception\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "def proto_loss(query_embs, prototypes, n_classes=6, n_query=1):\n",
    "    \n",
    "    dists = euclidean_dist(query_embs, prototypes)\n",
    "    log_p_y = F.log_softmax(-dists, dim=1).view(n_classes, n_query, -1)\n",
    "    \n",
    "    target_inds = torch.arange(0, n_classes)\n",
    "    target_inds = target_inds.view(n_classes, 1, 1)\n",
    "    target_inds = target_inds.expand(n_classes, n_query, 1).long().to(device)\n",
    "\n",
    "    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "    \n",
    "    return loss_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./koreanframenet/resource/info/fn1.7_frame2idx.json', 'r') as f:\n",
    "    frame2idx = json.load(f)\n",
    "with open('./koreanframenet/resource/info/fn1.7_frame_definitions.json', 'r') as f:\n",
    "    frame2definition = json.load(f)\n",
    "frame_prototype = torch.load('./data/frame_prototype.pt')\n",
    "    \n",
    "\n",
    "def get_definition_embs(input_senses):\n",
    "\n",
    "    frame_prototypes = []\n",
    "    for i in input_senses:\n",
    "        frame_idx = i.item()\n",
    "        frame = bert_io.idx2sense[frame_idx]\n",
    "    \n",
    "        proto = frame_prototype[frame]\n",
    "        frame_prototypes.append(proto)\n",
    "\n",
    "    frame_prototypes = torch.stack(frame_prototypes).view(-1, 768)\n",
    "    \n",
    "    return frame_prototypes\n",
    "\n",
    "# def get_prototype(b_input_senses, b_input_lus):\n",
    "\n",
    "#     with open('/disk/data/kaiser/kaiser/koreanframenet/resource/info/mul_lufrmap.json') as f:\n",
    "#         lufrmap = json.load(f)\n",
    "        \n",
    "#     y = []\n",
    "#     frame_prototypes = []\n",
    "#     for i in b_input_senses:\n",
    "#         frame_idx = i.item()\n",
    "#         y.append(frame_idx)\n",
    "        \n",
    "#         frame = bert_io.idx2sense[frame_idx]\n",
    "#         proto = frame_prototype[frame]\n",
    "#         frame_prototypes.append(proto)\n",
    "\n",
    "#     frame_prototypes = torch.stack(frame_prototypes).view(-1, 768)\n",
    "    \n",
    "#     return frame_prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distil(PRETRAINED_MODEL=\"bert-base-multilingual-cased\", \n",
    "          temperature=2.0, alpha_distilling=0.2, alpha_parsing=0.8, \n",
    "          model_dir=False, epoch=50):\n",
    "\n",
    "#     print('original model:', 'BERT-multilingual-base')\n",
    "    print('\\n\\tyour model would be saved at', model_dir)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # MLP for frame prototype\n",
    "    model_path = '/disk/data/models/framenet/prototype_mlp/prototype_mlp.pth'\n",
    "    mlp_model = MLP()\n",
    "    mlp_model.to(device)\n",
    "    mlp_model.load_state_dict(torch.load(model_path))\n",
    "#     mlp_model.eval()\n",
    "    \n",
    "    # FrameBERT_ko model\n",
    "    frameBERT_dir = '/disk/data/models/frameBERT/frameBERT_en'\n",
    "#     frameBERT_dir = '/disk/data/models/framenet_old/enModel-with-exemplar/14/'\n",
    "    print('original model:', frameBERT_dir)\n",
    "    \n",
    "    teacher = BertForJointShallowSemanticParsing.from_pretrained(frameBERT_dir, \n",
    "                                                                 num_senses = len(bert_io.sense2idx), \n",
    "                                                                 num_args = len(bert_io.bio_arg2idx),\n",
    "                                                                 lufrmap=bert_io.lufrmap, \n",
    "                                                                 frargmap = bert_io.bio_frargmap,\n",
    "                                                                 return_pooled_output=True)\n",
    "    \n",
    "    model = BertForJointShallowSemanticParsing.from_pretrained(frameBERT_dir, \n",
    "                                                               num_senses = len(bert_io.sense2idx), \n",
    "                                                               num_args = len(bert_io.bio_arg2idx),\n",
    "                                                               lufrmap=bert_io.lufrmap, \n",
    "                                                               frargmap = bert_io.bio_frargmap, \n",
    "                                                               return_pooled_output=True)\n",
    "    \n",
    "    teacher.to(device)\n",
    "    model.to(device)  \n",
    "\n",
    "    tic()\n",
    "    print('\\n### converting data to BERT input...')\n",
    "    trn_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(trn)\n",
    "    print('\\t ...is done:', tac())\n",
    "    print('\\t#of instance:', len(trn), len(trn_data))\n",
    "    sampler = RandomSampler(trn)\n",
    "    trn_dataloader = DataLoader(trn_data, sampler=sampler, batch_size=batch_size)\n",
    "    \n",
    "    # load optimizer\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.classifier.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "    optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "    \n",
    "        \n",
    "    max_grad_norm = 1.0\n",
    "    num_of_epoch = 0\n",
    "    accuracy_result = []\n",
    "    \n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        \n",
    "        # TRAIN loop\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(trn_dataloader):\n",
    "#             mlp_model.eval()\n",
    "            mlp_model.train()\n",
    "            model.train()\n",
    "            teacher.eval()\n",
    "            \n",
    "            # add batch to gpu\n",
    "            torch.cuda.set_device(0)\n",
    "#             torch.cuda.set_device(device)\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_orig_tok_to_maps, b_input_lus, b_input_senses, b_input_args, b_token_type_ids, b_input_masks = batch                      \n",
    "            \n",
    "            # get prototypes for frames\n",
    "            query_embs = get_definition_embs(b_input_senses)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_logit, loss_teacher = teacher(b_input_ids, \n",
    "                                                    token_type_ids=b_token_type_ids, \n",
    "                                                    attention_mask=b_input_masks,\n",
    "                                                    lus=b_input_lus,\n",
    "                                                    senses=b_input_senses, \n",
    "                                                    args=b_input_args)\n",
    "            \n",
    "            pooled_output, loss_parsing = model(b_input_ids, \n",
    "                                                token_type_ids=b_token_type_ids, \n",
    "                                                attention_mask=b_input_masks,\n",
    "                                                lus=b_input_lus,\n",
    "                                                senses=b_input_senses, \n",
    "                                                args=b_input_args)\n",
    "            \n",
    "#             with torch.no_grad():\n",
    "            teacher_logit = mlp_model(teacher_logit)\n",
    "            student_logit = mlp_model(pooled_output)\n",
    "            \n",
    "            loss_distilling = (\n",
    "                KD_loss(\n",
    "                    F.log_softmax(student_logit / temperature, dim=-1),\n",
    "                    F.softmax(teacher_logit / temperature, dim=-1),            \n",
    "                )\n",
    "                * temperature **2\n",
    "            )\n",
    "\n",
    "#             loss_distilling = proto_loss(prototypes, query_embs, n_classes=len(prototypes))\n",
    "            \n",
    "            loss = alpha_distilling * loss_distilling + alpha_parsing * loss_parsing\n",
    "            \n",
    "            loss.backward()\n",
    "            # track train loss\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "            model.zero_grad()\n",
    "            mlp_model.zero_grad()\n",
    "    \n",
    "#             break\n",
    "\n",
    "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "        \n",
    "#         break\n",
    "#         save your model\n",
    "        model_saved_path = model_dir+str(num_of_epoch)+'/'\n",
    "        print('\\n\\tyour model is saved:', model_saved_path)\n",
    "        if not os.path.exists(model_saved_path):\n",
    "            os.makedirs(model_saved_path)\n",
    "        model.save_pretrained(model_saved_path)\n",
    "        \n",
    "        num_of_epoch += 1\n",
    "\n",
    "        \n",
    "#         break\n",
    "    print('...training is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = 'framenet'\n",
    "masking = True\n",
    "MAX_LEN = 256\n",
    "batch_size = 3\n",
    "PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "fnversion = '1.7'\n",
    "language = 'multi'\n",
    "epochs = 50\n",
    "\n",
    "# by 100%\n",
    "\n",
    "model_dir = '/disk/data/models/framenet/withProto-100/'\n",
    "trn, dev, tst = dataio.load_data(srl=srl, language='ko')\n",
    "# trn = random.sample(trn, k=100)\n",
    "\n",
    "# with open('./trn_10per.json','r') as f:\n",
    "#     trn = json.load(f)\n",
    "# epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### TRAINING\n",
      "MODEL: framenet\n",
      "LANGUAGE: multi\n",
      "PRETRAINED BERT: bert-base-multilingual-cased\n",
      "training data:\n",
      "\t(ko): 1783\n",
      "BATCH_SIZE: 3\n",
      "MAX_LEN: 256\n",
      "\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "\n",
      "\tyour model would be saved at /disk/data/models/framenet/withProto-100/\n",
      "original model: /disk/data/models/frameBERT/frameBERT_en\n",
      "\n",
      "### converting data to BERT input...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ...is done: 0hour:0min:3sec\n",
      "\t#of instance: 1783 1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.5648391488720388\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   2%|▏         | 1/50 [03:20<2:43:45, 200.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.033322844335011\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   4%|▍         | 2/50 [07:02<2:45:32, 206.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7304890503652958\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|▌         | 3/50 [10:44<2:45:39, 211.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.49488319145405996\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   8%|▊         | 4/50 [14:26<2:44:35, 214.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.36292482578203455\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 5/50 [18:09<2:42:44, 216.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24626286782699974\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█▏        | 6/50 [21:51<2:40:25, 218.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18557021789127537\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/6/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 7/50 [25:34<2:37:36, 219.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1376477698944196\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/7/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  16%|█▌        | 8/50 [29:16<2:34:24, 220.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10593194990348415\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/8/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  18%|█▊        | 9/50 [32:57<2:30:51, 220.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08919540489202037\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/9/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 10/50 [36:39<2:27:19, 221.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0689533420721022\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/10/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  22%|██▏       | 11/50 [40:21<2:23:47, 221.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05516503365131236\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/11/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  24%|██▍       | 12/50 [44:02<2:20:07, 221.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04687382420759742\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/12/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  26%|██▌       | 13/50 [47:40<2:15:45, 220.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04437313569600091\n",
      "\n",
      "\tyour model is saved: /disk/data/models/framenet/withProto-100/13/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  28%|██▊       | 14/50 [51:18<2:11:44, 219.57s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8995a9975f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbert_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_BERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfnversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRETRAINED_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m train_distil(temperature=2.0, alpha_distilling=0.5, alpha_parsing=0.5, \n\u001b[0;32m---> 20\u001b[0;31m       model_dir=model_dir, epoch=epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3b0d939de52a>\u001b[0m in \u001b[0;36mtrain_distil\u001b[0;34m(PRETRAINED_MODEL, temperature, alpha_distilling, alpha_parsing, model_dir, epoch)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# track train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnb_tr_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mnb_tr_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model_dir = '/disk/data/models/framenet/proto_distilling_0109/'\n",
    "\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language='ko')\n",
    "# trn = random.sample(trn, k=10)\n",
    "# language = 'multi'\n",
    "\n",
    "print('')\n",
    "print('### TRAINING')\n",
    "print('MODEL:', srl)\n",
    "print('LANGUAGE:', language)\n",
    "print('PRETRAINED BERT:', PRETRAINED_MODEL)\n",
    "print('training data:')\n",
    "print('\\t(ko):', len(trn))\n",
    "print('BATCH_SIZE:', batch_size)\n",
    "print('MAX_LEN:', MAX_LEN)\n",
    "print('')\n",
    "\n",
    "bert_io = utils.for_BERT(mode='train', srl=srl, language=language, masking=masking, fnversion=fnversion, pretrained=PRETRAINED_MODEL)\n",
    "train_distil(temperature=2.0, alpha_distilling=0.5, alpha_parsing=0.5, \n",
    "      model_dir=model_dir, epoch=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
