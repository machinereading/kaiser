{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from transformers import *\n",
    "from kaiser.src import utils\n",
    "from kaiser.src import dataio\n",
    "from kaiser.src.modeling import BertForJointShallowSemanticParsing\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srl = 'framenet'\n",
    "srl = 'propbank-dp'\n",
    "language = 'ko'\n",
    "# language = 'en'\n",
    "masking = True\n",
    "# model_dir = '/disk/data/models/enframenet_1105/'\n",
    "model_dir = '/disk/data/models/kosrl_1116/'\n",
    "if language == 'en':\n",
    "    fnversion = 1.7\n",
    "#     PRETRAINED_MODEL = \"bert-large-cased\"\n",
    "    MAX_LEN = 256\n",
    "    batch_size = 6\n",
    "    PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "else:\n",
    "    fnversion = 1.1\n",
    "    PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "    MAX_LEN = 256\n",
    "    batch_size = 6\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of instances in trn: 19306\n",
      "# of instances in dev: 0\n",
      "# of instances in tst: 3778\n",
      "data example: [['한국탁구가', '2000년', '시드니올림픽', '본선에', '남녀복식', '2개조씩을', '<tgt>', '파견할', '</tgt>', '수', '있게', '됐다.'], ['_', '_', '_', '_', '_', '_', '_', 'PRED', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '파견.01', '_', '_', '_', '_'], ['ARG0', 'O', 'O', 'ARG2', 'O', 'ARG1', 'X', 'O', 'X', 'O', 'AUX', 'AUX']]\n",
      "\n",
      "MODEL: propbank-dp\n",
      "LANGUAGE: ko\n"
     ]
    }
   ],
   "source": [
    "trn, dev, tst = dataio.load_data(srl=srl, language=language)\n",
    "print('')\n",
    "print('MODEL:', srl)\n",
    "print('LANGUAGE:', language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_io = utils.for_BERT(mode='train', srl=srl, language=language, masking=True, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print('your model would be saved at', model_dir)\n",
    "    \n",
    "    if srl == 'propbank-dp':\n",
    "        model = BertForJointShallowSemanticParsing.from_pretrained(PRETRAINED_MODEL, \n",
    "                                                         num_senses = len(bert_io.sense2idx), \n",
    "                                                         num_args = len(bert_io.arg2idx),\n",
    "                                                                  srl=srl,\n",
    "                                                                  masking=False)\n",
    "    else:\n",
    "        model = BertForJointShallowSemanticParsing.from_pretrained(PRETRAINED_MODEL, \n",
    "                                                         num_senses = len(bert_io.sense2idx), \n",
    "                                                         num_args = len(bert_io.bio_arg2idx),\n",
    "                                                         lufrmap=bert_io.lufrmap, frargmap = bert_io.bio_frargmap)\n",
    "    model.to(device);\n",
    "    \n",
    "    trn_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(trn)\n",
    "    sampler = RandomSampler(trn)\n",
    "    trn_dataloader = DataLoader(trn_data, sampler=sampler, batch_size=batch_size)\n",
    "    \n",
    "    # load optimizer\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.classifier.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "    optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "    \n",
    "    max_grad_norm = 1.0\n",
    "    num_of_epoch = 0\n",
    "    accuracy_result = []\n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        # TRAIN loop\n",
    "        model.train()\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(trn_dataloader):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_orig_tok_to_maps, b_input_lus, b_input_senses, b_input_args, b_input_masks = batch            \n",
    "            # forward pass\n",
    "            loss = model(b_input_ids, token_type_ids=None, lus=b_input_lus, senses=b_input_senses, args=b_input_args,\n",
    "                         attention_mask=b_input_masks)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # track train loss\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            \n",
    "#             break\n",
    "\n",
    "        # print train loss per epoch\n",
    "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "        model_saved_path = model_dir+'epoch-'+str(num_of_epoch)+'-joint.pt'        \n",
    "        torch.save(model, model_saved_path)\n",
    "        num_of_epoch += 1\n",
    "        \n",
    "#         break\n",
    "    print('...training is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your model would be saved at /disk/data/models/kosrl_1115/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1115 17:06:09.292515 139682985780992 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/hahmyg/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
      "I1115 17:06:09.297170 139682985780992 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I1115 17:06:10.603473 139682985780992 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/hahmyg/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "I1115 17:06:16.204210 139682985780992 modeling_utils.py:405] Weights of BertForJointShallowSemanticParsing not initialized from pretrained model: ['sense_classifier.weight', 'sense_classifier.bias', 'arg_classifier.weight', 'arg_classifier.bias']\n",
      "I1115 17:06:16.204819 139682985780992 modeling_utils.py:408] Weights from pretrained model not used in BertForJointShallowSemanticParsing: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/disk/kaiser/kaiser/src/utils.py\u001b[0m in \u001b[0;36mget_masks\u001b[0;34m(datas, mapdata, num_label, masking)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmasking\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-6114ad252884>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             loss = model(b_input_ids, token_type_ids=None, lus=b_input_lus, senses=b_input_senses, args=b_input_args,\n\u001b[0;32m---> 49\u001b[0;31m                          attention_mask=b_input_masks)\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/src/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, lus, senses, args, using_gold_fame, position_ids, head_mask)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0marg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mlufr_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlufrmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_senses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msense_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# loss for sense id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/src/utils.py\u001b[0m in \u001b[0;36mget_masks\u001b[0;34m(datas, mapdata, num_label, masking)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;31m#         mask[mask==0] = np.NINF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mcandis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flat_accuracy(preds, labels):\n",
    "#     pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "#     labels_flat = labels.flatten()\n",
    "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# def test(prefix):\n",
    "#     result_path = '/disk/data/models/'+prefix+'/'\n",
    "#     if not os.path.exists(result_path):\n",
    "#         os.makedirs(result_path)\n",
    "#     print('TEST result would be saved at:', result_path)\n",
    "#     models = glob.glob(model_dir+'*.pt')\n",
    "#     results = []\n",
    "#     tic()\n",
    "#     for m in models:\n",
    "        \n",
    "#         print('model:', m)\n",
    "#         model = torch.load(m)\n",
    "#         model.eval()\n",
    "\n",
    "#         tst_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(tst)\n",
    "#         sampler = RandomSampler(tst)\n",
    "#         tst_dataloader = DataLoader(tst_data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "#         eval_loss, eval_accuracy = 0, 0\n",
    "#         nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        \n",
    "#         pred_senses, true_senses, pred_args, true_args = [],[],[],[]\n",
    "#         for batch in tst_dataloader:\n",
    "#             batch = tuple(t.to(device) for t in batch)\n",
    "#             b_input_ids, b_orig_tok_to_maps, b_lus, b_senses, b_args, b_masks = batch\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 tmp_eval_loss = model(b_input_ids, token_type_ids=None, \n",
    "#                                      lus=b_lus, attention_mask=b_masks)\n",
    "#                 sense_logits, arg_logits = model(b_input_ids, token_type_ids=None, \n",
    "#                                 lus=b_lus, attention_mask=b_masks)\n",
    "#             sense_logits = sense_logits.detach().cpu().numpy()\n",
    "#             arg_logits = arg_logits.detach().cpu().numpy()\n",
    "            \n",
    "#             gold_sense_ids = b_senses.to('cpu').numpy()\n",
    "#             gold_arg_ids = b_args.to('cpu').numpy()\n",
    "#             input_ids = b_input_ids.to('cpu').numpy()\n",
    "#             lufr_masks = utils.get_masks(b_lus, bert_io.lufrmap, num_label=len(bert_io.sense2idx)).to(device)\n",
    "            \n",
    "#             for b_idx in range(len(sense_logits)):\n",
    "#                 input_id = input_ids[b_idx]\n",
    "#                 sense_logit = sense_logits[b_idx]\n",
    "#                 arg_logit = arg_logits[b_idx]\n",
    "#                 lufr_mask = lufr_masks[b_idx]\n",
    "#                 orig_tok_to_map = b_orig_tok_to_maps[b_idx]\n",
    "                \n",
    "#                 masked_sense_logit = utils.masking_logit(sense_logit, lufr_mask)\n",
    "#                 pred_sense, sense_score = utils.logit2label(masked_sense_logit)\n",
    "#                 frarg_mask = utils.get_masks([pred_sense], bert_io.bio_frargmap, num_label=len(bert_io.bio_arg2idx)).to(device)[0]\n",
    "\n",
    "#                 pred_arg_bert = []\n",
    "#                 for logit in arg_logit:\n",
    "#                     masked_logit = utils.masking_logit(logit, frarg_mask)\n",
    "#                     label, score = utils.logit2label(masked_logit)\n",
    "#                     pred_arg_bert.append(int(label))\n",
    "                 \n",
    "#                 #infer\n",
    "#                 pred_arg,true_arg = [],[]\n",
    "#                 for idx in orig_tok_to_map:\n",
    "#                     if idx != -1:\n",
    "#                         tok_id = int(input_id[idx])\n",
    "#                         if tok_id == 1:\n",
    "#                             pass\n",
    "#                         elif tok_id == 2:\n",
    "#                             pass\n",
    "#                         else:\n",
    "#                             pred_arg.append(pred_arg_bert[idx])\n",
    "#                             true_arg.append(gold_arg_ids[b_idx][idx])\n",
    "                \n",
    "#                 pred_senses.append([int(pred_sense)])\n",
    "#                 pred_args.append(pred_arg)\n",
    "#                 true_args.append(true_arg)\n",
    "#             true_senses.append(gold_sense_ids)\n",
    "            \n",
    "# #             break\n",
    "# #         break\n",
    "\n",
    "#         pred_sense_tags = [bert_io.idx2sense[p_i] for p in pred_senses for p_i in p]\n",
    "#         valid_sense_tags = [bert_io.idx2sense[l_ii] for l in true_senses for l_i in l for l_ii in l_i]\n",
    "        \n",
    "#         pred_arg_tags = [[bert_io.idx2bio_arg[p_i] for p_i in p] for p in pred_args]\n",
    "#         valid_arg_tags = [[bert_io.idx2bio_arg[v_i] for v_i in v] for v in true_args]\n",
    "\n",
    "# #         acc = accuracy_score(pred_sense_tags, valid_sense_tags)\n",
    "# #         f1 = f1_score(pred_arg_tags, valid_arg_tags)\n",
    "# #         print(\"SenseId Accuracy: {}\".format(accuracy_score(pred_sense_tags, valid_sense_tags)))\n",
    "# #         print(\"ArgId F1: {}\".format(f1_score(pred_arg_tags, valid_arg_tags)))\n",
    "\n",
    "#         acc = accuracy_score(valid_sense_tags, pred_sense_tags)\n",
    "#         arg_f1 = f1_score(valid_arg_tags, pred_arg_tags)\n",
    "#         arg_p = precision_score(valid_arg_tags, pred_arg_tags)\n",
    "#         arg_r = recall_score(valid_arg_tags, pred_arg_tags)\n",
    "\n",
    "# #         full_f1 = f1_score(gold_full_all, pred_full_all)\n",
    "# #         full_p = precision_score(gold_full_all, pred_full_all)\n",
    "# #         full_r = recall_score(gold_full_all, pred_full_all)\n",
    "#         print(\"SenseId Accuracy: {}\".format(acc))\n",
    "#         print(\"ArgId P: {}\".format(arg_p))\n",
    "#         print(\"ArgId R: {}\".format(arg_r))\n",
    "#         print(\"ArgId F1: {}\".format(arg_f1))\n",
    "#         print('-----processing time:', tac(), '\\n')\n",
    "              \n",
    "        \n",
    "#         result = m+'\\tsenseid:'+str(acc)+'\\targid P:'+str(arg_p)+'\\targid R:'+str(arg_r)+'\\targid F1:'+str(arg_f1)+'\\n'\n",
    "#         results.append(result)\n",
    "        \n",
    "#         epoch = m.split('-')[1]\n",
    "#         fname = result_path+str(epoch)+'-result.txt'\n",
    "#         with open(fname, 'w') as f:\n",
    "#             line = result\n",
    "#             f.write(line)\n",
    "#             line = 'gold'+'\\t'+'pred'+'\\n'\n",
    "#             f.write(line)\n",
    "#             for r in range(len(pred_sense_tags)):\n",
    "#                 line = valid_sense_tags[r] + '\\t' + pred_sense_tags[r]+'\\n'\n",
    "#                 f.write(line)\n",
    "#                 line = str(valid_arg_tags[r]) + '\\t' + str(pred_arg_tags[r])+'\\n'\n",
    "#                 f.write(line)\n",
    "#     fname = result_path+'result.txt'\n",
    "#     with open(fname, 'w') as f:\n",
    "#         for r in results:\n",
    "#             f.write(r)\n",
    "\n",
    "#     print('result is written to', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srl = 'framenet'\n",
    "# # srl = 'propbank-dp'\n",
    "# language = 'ko'\n",
    "# # language = 'en'\n",
    "# masking = True\n",
    "# model_dir = '/disk/data/models/koframenet_1105/'\n",
    "# if language == 'en':\n",
    "#     fnversion = 1.7\n",
    "# #     PRETRAINED_MODEL = \"bert-large-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "# else:\n",
    "#     fnversion = 1.1\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "\n",
    "# epochs = 50\n",
    "\n",
    "# bert_io = utils.for_BERT(mode='train', srl=srl, language=language, masking=True, fnversion=fnversion)\n",
    "\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language)\n",
    "# print('')\n",
    "# print('MODEL:', srl)\n",
    "# print('LANGUAGE:', language)\n",
    "\n",
    "\n",
    "# prefix = 'koModel_for_ko'\n",
    "# test(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srl = 'framenet'\n",
    "# # srl = 'propbank-dp'\n",
    "# language = 'ko'\n",
    "# # language = 'en'\n",
    "# masking = True\n",
    "# model_dir = '/disk/data/models/enframenet_1105/'\n",
    "# if language == 'en':\n",
    "#     fnversion = 1.7\n",
    "# #     PRETRAINED_MODEL = \"bert-large-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "# else:\n",
    "#     fnversion = 1.1\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "\n",
    "# epochs = 50\n",
    "\n",
    "# bert_io = utils.for_BERT(mode='train', srl=srl, language=language, masking=True, fnversion=fnversion)\n",
    "\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language)\n",
    "# print('')\n",
    "# print('MODEL:', srl)\n",
    "# print('LANGUAGE:', language)\n",
    "\n",
    "# prefix = 'enModel_for_ko'\n",
    "# test(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srl = 'framenet'\n",
    "# # srl = 'propbank-dp'\n",
    "# # language = 'ko'\n",
    "# language = 'en'\n",
    "# masking = True\n",
    "# model_dir = '/disk/data/models/enframenet_1105/'\n",
    "# if language == 'en':\n",
    "#     fnversion = 1.7\n",
    "# #     PRETRAINED_MODEL = \"bert-large-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "# else:\n",
    "#     fnversion = 1.1\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "\n",
    "# epochs = 50\n",
    "\n",
    "# bert_io = utils.for_BERT(mode='train', srl=srl, language=language, masking=True, fnversion=fnversion)\n",
    "\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language)\n",
    "# print('')\n",
    "# print('MODEL:', srl)\n",
    "# print('LANGUAGE:', language)\n",
    "\n",
    "# prefix = 'enModel_for_en'\n",
    "# test(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srl = 'framenet'\n",
    "# # srl = 'propbank-dp'\n",
    "# # language = 'ko'\n",
    "# language = 'en'\n",
    "# masking = True\n",
    "# model_dir = '/disk/data/models/koframenet_1105/'\n",
    "# if language == 'en':\n",
    "#     fnversion = 1.7\n",
    "# #     PRETRAINED_MODEL = \"bert-large-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "# else:\n",
    "#     fnversion = 1.1\n",
    "#     PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "#     MAX_LEN = 256\n",
    "#     batch_size = 6\n",
    "\n",
    "# epochs = 50\n",
    "\n",
    "# bert_io = utils.for_BERT(mode='train', srl=srl, language=language, masking=True, fnversion=fnversion)\n",
    "\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language)\n",
    "# print('')\n",
    "# print('MODEL:', srl)\n",
    "# print('LANGUAGE:', language)\n",
    "\n",
    "# prefix = 'koModel_for_en'\n",
    "# test(prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
