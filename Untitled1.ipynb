{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src import prototypical_batch_sampler\n",
    "from collections import Counter, OrderedDict\n",
    "from kaiser.src import dataio\n",
    "from kaiser.src import utils\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "import sys\n",
    "import random\n",
    "\n",
    "sys.path.insert(0,'../')\n",
    "sys.path.insert(0,'../../')\n",
    "\n",
    "from kaiser.src.modeling import BertForJointShallowSemanticParsing, FrameBERT\n",
    "from pprint import pprint\n",
    "\n",
    "from kaiser.src.prototypical_loss import prototypical_loss as loss_fn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    }
   ],
   "source": [
    "bert_io = utils.for_BERT(mode='train', language='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of instances in trn: 19391\n",
      "# of instances in dev: 2272\n",
      "# of instances in tst: 6714\n",
      "data example: [['Greece', 'wildfires', 'force', 'thousands', 'to', '<tgt>', 'evacuate', '</tgt>'], ['_', '_', '_', '_', '_', '_', 'evacuate.v', '_'], ['_', '_', '_', '_', '_', '_', 'Escaping', '_'], ['O', 'O', 'O', 'B-Escapee', 'O', 'X', 'O', 'X']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0hour:0min:3sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic()\n",
    "trn, dev, tst = dataio.load_data(srl='framenet', language='en', exem=False)\n",
    "trn = random.sample(trn, k=500)\n",
    "tst = random.sample(tst, k=100)\n",
    "trn_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(trn)\n",
    "tst_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(tst)\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./koreanframenet/resource/info/fn1.7_frame2idx.json', 'r') as f:\n",
    "    frame2idx = json.load(f)\n",
    "with open('./koreanframenet/resource/info/fn1.7_frame_definitions.json', 'r') as f:\n",
    "    frame2definition = json.load(f)\n",
    "\n",
    "def_data, def_y = bert_io.convert_to_bert_input_label_definition(frame2definition, frame2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(data):\n",
    "    y = []\n",
    "    for instance in data:\n",
    "        frame = False\n",
    "        for i in instance[2]:\n",
    "            if i != '_':\n",
    "                frame = i\n",
    "                break\n",
    "        frameidx = frame2idx[frame]\n",
    "        y.append(frameidx)\n",
    "    return tuple(y)\n",
    "\n",
    "with open('./koreanframenet/resource/info/fn1.7_frame2idx.json', 'r') as f:\n",
    "    frame2idx = json.load(f)\n",
    "\n",
    "\n",
    "all_y = dict(Counter(get_y(trn)))\n",
    "target_frames = []\n",
    "for i in all_y:\n",
    "    count = all_y[i]\n",
    "    if count >= 2:\n",
    "        target_frames.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    }
   ],
   "source": [
    "d = prototypical_batch_sampler.PrototypicalBatchSampler(classes_per_it_tr=4, classes_per_it_val=2,\n",
    "                                                        num_support_tr=2, num_support_val=2, \n",
    "                                                        target_frames=target_frames, \n",
    "                                                        def_data=def_data, def_y=def_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y = d.get_y(trn)\n",
    "# tst_y = d.get_y(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_batch = d.gen_batch(trn_data, trn_y, mode='train')\n",
    "# tst_batch = d.gen_batch(tst, tst_y, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frameBERT_dir = '/disk/data/models/frameBERT/frameBERT_en'\n",
    "\n",
    "frameBERT = FrameBERT.from_pretrained(frameBERT_dir,\n",
    "                                      num_senses = len(bert_io.sense2idx), \n",
    "                                      num_args = len(bert_io.bio_arg2idx),\n",
    "                                      lufrmap=bert_io.lufrmap, \n",
    "                                      frargmap = bert_io.bio_frargmap)\n",
    "\n",
    "frameBERT.to(device)\n",
    "frameBERT.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "mlp_model = MLP()\n",
    "mlp_model.to(device)\n",
    "mlp_model.train()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes\n",
      "tensor([ 524,  505, 1121, 1142])\n",
      "support_idxs\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7]])\n",
      "\n",
      "prototypes\n",
      "tensor([[-0.2642,  0.1758, -0.1155,  ...,  0.1528,  0.0091,  0.1088],\n",
      "        [-0.3860,  0.0462, -0.1096,  ...,  0.0209,  0.3764,  0.0566],\n",
      "        [-0.4127,  0.1546, -0.0004,  ..., -0.0424,  0.0542, -0.2226],\n",
      "        [-0.3157,  0.1858,  0.1979,  ...,  0.1914, -0.0928, -0.0042]],\n",
      "       device='cuda:0', grad_fn=<CopyBackwards>)\n",
      "query_embs\n",
      "tensor([[-0.6290,  0.0325,  0.0662,  ...,  0.1483,  0.0024, -0.1080],\n",
      "        [-0.6205,  0.0480, -0.0288,  ...,  0.1163,  0.0429,  0.0696],\n",
      "        [-0.6698,  0.0900,  0.0536,  ...,  0.1522, -0.0614, -0.0286],\n",
      "        [-0.4019,  0.0774,  0.1149,  ...,  0.1429, -0.0161, -0.1366]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor(3.0586, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for episode in trn_batch:\n",
    "    support_embs = []\n",
    "    query_embs = []\n",
    "    \n",
    "    support_y, query_y = [],[]\n",
    "    \n",
    "    for class_indice in episode:\n",
    "        support_examples, query_examples = class_indice\n",
    "\n",
    "        query_inputs, _, query_token_type_ids, query_masks = query_examples[0][0]\n",
    "        query_inputs = query_inputs.view(1,len(query_inputs)).to(device)\n",
    "        query_token_type_ids = query_token_type_ids.view(1,len(query_token_type_ids)).to(device)\n",
    "        query_masks = query_masks.view(1,len(query_masks)).to(device)\n",
    "        \n",
    "        query_frame = query_examples[0][1]\n",
    "        query_y.append(query_frame)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            _, query_emb = frameBERT(query_inputs, \n",
    "                                  token_type_ids=query_token_type_ids, \n",
    "                                  attention_mask=query_masks)\n",
    "            query_emb = query_emb.view(-1)\n",
    "        query_embs.append(query_emb)\n",
    "        \n",
    "        support_inputs, support_token_type_ids, support_masks = [],[],[]\n",
    "        for i in range(len(support_examples)):\n",
    "            support_input, _, _, _, _, support_token_type_id, support_mask = support_examples[i][0]\n",
    "            support_inputs.append(support_input)\n",
    "            support_token_type_ids.append(support_token_type_id)\n",
    "            support_masks.append(support_mask)\n",
    "            \n",
    "            support_frame = support_examples[i][1]\n",
    "            support_y.append(support_frame)\n",
    "            \n",
    "            \n",
    "            \n",
    "        support_inputs = torch.stack(support_inputs).to(device)\n",
    "        support_token_type_ids = torch.stack(support_token_type_ids).to(device)\n",
    "        support_masks = torch.stack(support_masks).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, support_emb = frameBERT(support_inputs, \n",
    "                                  token_type_ids=support_token_type_ids, \n",
    "                                  attention_mask=support_masks)\n",
    "        support_embs.append(support_emb)\n",
    "        \n",
    "    support_embs = torch.stack(support_embs)\n",
    "    support_embs = support_embs.view(-1, 768)\n",
    "    query_embs = torch.stack(query_embs)\n",
    "    \n",
    "    support_embs = mlp_model(support_embs)\n",
    "    query_embs = mlp_model(query_embs)\n",
    "    \n",
    "    support_y = tuple(support_y)\n",
    "    query_y = tuple(query_y)\n",
    "    \n",
    "    n_support = 2\n",
    "    loss_val, acc_val = loss_fn(support_embs, query_embs, support_y, query_y, n_support)\n",
    "    \n",
    "    print(loss_val)\n",
    "    print(acc_val)\n",
    "            \n",
    "#         s, q = [],[]\n",
    "#         for i in range(len(support_examples)):\n",
    "#             support_example = support_examples[i]\n",
    "            \n",
    "#             print('1')\n",
    "#             print(len(support_example[0]))\n",
    "#             print(support_example[0][0])\n",
    "#             print(support_example[1])\n",
    "#             print('end')\n",
    "# #             break\n",
    "        \n",
    "#         print('support_examples')\n",
    "#         print(len(support_examples))\n",
    "#         print(support_examples)\n",
    "        \n",
    "#         print('query_examples')\n",
    "#         print(len(query_examples))\n",
    "#         print(query_examples)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = torch.rand(4, 2,768)\n",
    "# print(z)\n",
    "# print(z.size())\n",
    "\n",
    "# k = z.view(-1, 768)\n",
    "# print(k)\n",
    "# print(k.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = dict(Counter(d.trn_y))\n",
    "# print(len(z))\n",
    "\n",
    "# r = []\n",
    "# for i in z:\n",
    "#     count = z[i]\n",
    "#     if count >=5:\n",
    "#         r.append(i)\n",
    "# with open('./data/target_frames.json','w') as f:\n",
    "#     json.dump(r, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = (0,1,2)\n",
    "\n",
    "# for i in range(len(a)):\n",
    "#     print(i, a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de = d.def_data[0]\n",
    "# print(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = d.trn[2]\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in s[1]:\n",
    "#     if i != '_':\n",
    "#         frame = i\n",
    "#         break\n",
    "# print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in d.frame2idx:\n",
    "#     idx = d.frame2idx[f]\n",
    "#     defi = d.frameidx2definition(idx)\n",
    "#     print(defi)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
