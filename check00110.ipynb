{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n",
      "\n",
      "\t###DEVICE: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import parser\n",
    "from src import dataio\n",
    "import glob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "import random\n",
    "\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "with open('./data/frame_coreFE_list.json','r') as f:\n",
    "    frame_coreFE = json.load(f)\n",
    "\n",
    "def weighting(frame, args):\n",
    "    weighted_args = []\n",
    "    for arg in args:\n",
    "        weighted_args.append(arg)\n",
    "        if arg in frame_coreFE[frame]:\n",
    "            weighted_args.append(arg)\n",
    "        else:\n",
    "            pass\n",
    "    return weighted_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(srl=False, masking=False, viterbi=False, language=False, model_path=False, \n",
    "         result_dir=False, train_lang=False, tgt=False,\n",
    "         pretrained=\"bert-base-multilingual-cased\"):\n",
    "    if not result_dir:\n",
    "        result_dir = '/disk/data/models/'+model_dir.split('/')[-2]+'-result/'\n",
    "    else:\n",
    "        pass\n",
    "    if result_dir[-1] != '/':\n",
    "        result_dir = result_dir+'/'\n",
    "        \n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "        \n",
    "    if not train_lang:\n",
    "        train_lang = language\n",
    "    \n",
    "    fname = fname = result_dir+train_lang+'_for_'+language\n",
    "        \n",
    "    if masking:\n",
    "        fname = fname + '_with_masking_result.txt'\n",
    "    else:\n",
    "        fname = fname +'_result.txt'\n",
    "        \n",
    "    print('### Your result would be saved to:', fname)\n",
    "        \n",
    "    trn, dev, tst = dataio.load_data(srl=srl, language=language, exem=False)\n",
    "    \n",
    "    print('### EVALUATION')\n",
    "    print('MODE:', srl)\n",
    "    print('target LANGUAGE:', language)\n",
    "    print('trained LANGUAGE:', train_lang)\n",
    "    print('Viterbi:', viterbi)\n",
    "    print('masking:', masking)\n",
    "    print('using TGT token:', tgt)\n",
    "    tic()    \n",
    "    \n",
    "    models = [model_path]\n",
    "        \n",
    "#     models = glob.glob(model_path+'*/')\n",
    "    \n",
    "#     models = []\n",
    "    \n",
    "    # en_exemplar best\n",
    "#     models.append('/disk/data/models/dict_framenet/enModel-with-exemplar/9/')\n",
    "#     models.append('/disk/data/models/frameBERT/frameBERT_en/')\n",
    "    \n",
    "#     # ko best\n",
    "#     models.append('/disk/data/models/framenet/koModel/35/')\n",
    "    \n",
    "    # mul best\n",
    "#     models.append('/disk/data/models/framenet_old/mulModel-100/39/')\n",
    "#     models.append('/disk/data/models/dict_framenet/mulModel-100/39/')\n",
    "\n",
    "#     mul best\n",
    "#     models.append('/disk/data/models/framenet_old/mulModel-100/39/')\n",
    "#     models.append(model_path+'36/')\n",
    "#     models.append(model_path+'37/')\n",
    "    \n",
    "    eval_result = []\n",
    "    for m in models:\n",
    "#         m = '/disk/data/models/framenet/enModel-with-exemplar/epoch-8-joint.pt'\n",
    "        print('### model dir:', m)\n",
    "        print('### TARGET LANGUAGE:', language)\n",
    "        torch.cuda.set_device(device)\n",
    "        model = parser.ShallowSemanticParser(srl=srl,gold_pred=True, model_path=m, viterbi=viterbi, \n",
    "                                             masking=masking, language='multilingual', tgt=tgt,\n",
    "                                             pretrained=pretrained)\n",
    "\n",
    "        gold_senses, pred_senses, gold_args, pred_args = [],[],[],[]        \n",
    "        gold_full_all, pred_full_all = [],[]\n",
    "\n",
    "        for instance in tst:\n",
    "            torch.cuda.set_device(device)\n",
    "#             try:\n",
    "            result = model.parser(instance)\n",
    "\n",
    "            gold_sense = [i for i in instance[2] if i != '_'][0]\n",
    "            pred_sense = [i for i in result[0][2] if i != '_'][0]\n",
    "\n",
    "\n",
    "            gold_arg = [i for i in instance[3] if i != 'X']\n",
    "            pred_arg = [i for i in result[0][3]]\n",
    "\n",
    "            gold_senses.append(gold_sense)\n",
    "            pred_senses.append(pred_sense)\n",
    "            \n",
    "            gold_args.append(gold_arg)\n",
    "            pred_args.append(pred_arg)\n",
    "\n",
    "            if srl == 'framenet':\n",
    "                gold_full = []\n",
    "                gold_full.append(gold_sense)\n",
    "                gold_full.append(gold_sense)\n",
    "                weighted_gold_args = weighting(gold_sense, gold_arg)\n",
    "                gold_full += weighted_gold_args\n",
    "\n",
    "                pred_full = []\n",
    "                pred_full.append(pred_sense)\n",
    "                pred_full.append(pred_sense)\n",
    "                weighted_pred_args = weighting(pred_sense, pred_arg)\n",
    "                pred_full += weighted_pred_args\n",
    "\n",
    "                gold_full_all.append(gold_full)\n",
    "                pred_full_all.append(pred_full)\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "                    \n",
    "#             except KeyboardInterrupt:\n",
    "#                 raise\n",
    "#             except:\n",
    "#                 print(\"cuda error\")\n",
    "#                 pass\n",
    "            \n",
    "#             break\n",
    "            \n",
    "        acc = accuracy_score(gold_senses, pred_senses)\n",
    "        arg_f1 = f1_score(gold_args, pred_args)\n",
    "        arg_precision = precision_score(gold_args, pred_args)\n",
    "        arg_recall = recall_score(gold_args, pred_args)\n",
    "        \n",
    "\n",
    "#         epoch = m.split('/')[-1].split('-')[1]\n",
    "        epoch = m.split('/')[-2]\n",
    "        print('# EPOCH:', epoch)\n",
    "        print(\"SenseId Accuracy: {}\".format(acc))\n",
    "        print(\"ArgId Precision: {}\".format(arg_precision))\n",
    "        print(\"ArgId Recall: {}\".format(arg_recall))\n",
    "        print(\"ArgId F1: {}\".format(arg_f1))\n",
    "        if srl == 'framenet':\n",
    "            full_f1 = f1_score(gold_full_all, pred_full_all)\n",
    "            full_precision = precision_score(gold_full_all, pred_full_all)\n",
    "            full_recall = recall_score(gold_full_all, pred_full_all)\n",
    "            print(\"full-structure Precision: {}\".format(full_precision))\n",
    "            print(\"full-structure Recall: {}\".format(full_recall))\n",
    "            print(\"full-structure F1: {}\".format(full_f1))\n",
    "        print('-----processing time:', tac())\n",
    "        print('')\n",
    "\n",
    "\n",
    "        model_result = []\n",
    "        model_result.append(epoch)\n",
    "        model_result.append(acc)\n",
    "        model_result.append(arg_precision)\n",
    "        model_result.append(arg_recall)\n",
    "        model_result.append(arg_f1)\n",
    "        if srl == 'framenet':\n",
    "            model_result.append(full_precision)\n",
    "            model_result.append(full_recall)\n",
    "            model_result.append(full_f1)\n",
    "        model_result = [str(i) for i in model_result]\n",
    "        eval_result.append(model_result)\n",
    "    \n",
    "    \n",
    "    with open(fname,'w') as f:\n",
    "        if srl == 'framenet':\n",
    "            f.write('epoch'+'\\t''SenseID'+'\\t'+'Arg_P'+'\\t'+'Arg_R'+'\\t'+'ArgF1'+'\\t'+'full_P'+'\\t'+'full_R'+'\\t'+'full_F1'+'\\n')\n",
    "        else:\n",
    "            f.write('epoch'+'\\t''SenseID'+'\\t'+'Arg_P'+'\\t'+'Arg_R'+'\\t'+'ArgF1'+'\\n')\n",
    "        for i in eval_result:\n",
    "            line = '\\t'.join(i)\n",
    "            f.write(line+'\\n')\n",
    "            \n",
    "        print('\\n\\t### Your result is saved at:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-25/29/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-25/29/\n",
      "/disk/data/models/framenet/proto_distilling-25/29/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 29\n",
      "SenseId Accuracy: 0.5208946439081813\n",
      "ArgId Precision: 0.2924757281553398\n",
      "ArgId Recall: 0.2981566250154646\n",
      "ArgId F1: 0.2952888562151565\n",
      "full-structure Precision: 0.38706071403619086\n",
      "full-structure Recall: 0.39201811491650157\n",
      "full-structure F1: 0.38952364211636487\n",
      "-----processing time: 0hour:6min:2sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-25/29/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-100/19/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-100/19/\n",
      "/disk/data/models/framenet/mulModel-100/19/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.6860898567784972\n",
      "ArgId Precision: 0.4223639154563703\n",
      "ArgId Recall: 0.44253371273042186\n",
      "ArgId F1: 0.4322136297728371\n",
      "full-structure Precision: 0.5307105027856112\n",
      "full-structure Recall: 0.5459949051797339\n",
      "full-structure F1: 0.5382442188971435\n",
      "-----processing time: 0hour:5min:58sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###eval for proto-distill (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling/39/'\n",
    "# result_dir = '/disk/data/models/eval_result_test'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-100/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-25/19/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-25/19/\n",
      "/disk/data/models/framenet/proto_distilling-25/19/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.5187365116735334\n",
      "ArgId Precision: 0.3143646408839779\n",
      "ArgId Recall: 0.2815786217988371\n",
      "ArgId F1: 0.2970697644064479\n",
      "full-structure Precision: 0.40569020021074814\n",
      "full-structure Recall: 0.38140390602887064\n",
      "full-structure F1: 0.3931723685170326\n",
      "-----processing time: 0hour:5min:55sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-25/39/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-25/39/\n",
      "/disk/data/models/framenet/mulModel-25/39/\n",
      "...model is loaded\n",
      "# EPOCH: 39\n",
      "SenseId Accuracy: 0.5136354718461841\n",
      "ArgId Precision: 0.30139797357958187\n",
      "ArgId Recall: 0.2907336385005567\n",
      "ArgId F1: 0.29596977329974816\n",
      "full-structure Precision: 0.3915515256188831\n",
      "full-structure Recall: 0.38501273705066513\n",
      "full-structure F1: 0.3882546025403168\n",
      "-----processing time: 0hour:6min:10sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-25/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-25/39/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-25/49/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-25/49/\n",
      "/disk/data/models/framenet/mulModel-25/49/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 49\n",
      "SenseId Accuracy: 0.51854031783402\n",
      "ArgId Precision: 0.26526494637357967\n",
      "ArgId Recall: 0.30904367190399606\n",
      "ArgId F1: 0.2854857142857143\n",
      "full-structure Precision: 0.36085194002959914\n",
      "full-structure Recall: 0.3968298896122276\n",
      "full-structure F1: 0.37798672193576655\n",
      "-----processing time: 0hour:6min:0sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-25/49/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-25/39/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-25/39/\n",
      "/disk/data/models/framenet/proto_distilling-25/39/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 39\n",
      "SenseId Accuracy: 0.5146164410437513\n",
      "ArgId Precision: 0.28413198087909525\n",
      "ArgId Recall: 0.3014969689471731\n",
      "ArgId F1: 0.29255702280912366\n",
      "full-structure Precision: 0.3767020697167756\n",
      "full-structure Recall: 0.3915227851684121\n",
      "full-structure F1: 0.3839694656488549\n",
      "-----processing time: 0hour:5min:56sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-25/39/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-10/19/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-10/19/\n",
      "/disk/data/models/framenet/proto_distilling-10/19/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.4226015303119482\n",
      "ArgId Precision: 0.24136287824636646\n",
      "ArgId Recall: 0.2506495113200544\n",
      "ArgId F1: 0.24591855313467254\n",
      "full-structure Precision: 0.31208307544185404\n",
      "full-structure Recall: 0.3211151995471271\n",
      "full-structure F1: 0.316534719073693\n",
      "-----processing time: 0hour:5min:56sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-10/19/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-10/19/\n",
      "/disk/data/models/framenet/mulModel-10/19/\n",
      "...model is loaded\n",
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.42672160094173045\n",
      "ArgId Precision: 0.23934226552984167\n",
      "ArgId Recall: 0.24310280836323148\n",
      "ArgId F1: 0.24120788068495674\n",
      "full-structure Precision: 0.3140397536394177\n",
      "full-structure Recall: 0.3175063685253326\n",
      "full-structure F1: 0.3157635467980296\n",
      "-----processing time: 0hour:6min:8sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-10/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-10/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-10/49/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-10/49/\n",
      "/disk/data/models/framenet/proto_distilling-10/49/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 49\n",
      "SenseId Accuracy: 0.4235824995095154\n",
      "ArgId Precision: 0.2502978160158835\n",
      "ArgId Recall: 0.2339477916615118\n",
      "ArgId F1: 0.24184678347614783\n",
      "full-structure Precision: 0.3237410071942446\n",
      "full-structure Recall: 0.3120577412963487\n",
      "full-structure F1: 0.3177920299776608\n",
      "-----processing time: 0hour:5min:54sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-10/49/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-10/49/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-10/49/\n",
      "/disk/data/models/framenet/mulModel-10/49/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 49\n",
      "SenseId Accuracy: 0.4300568962134589\n",
      "ArgId Precision: 0.2256283106052068\n",
      "ArgId Recall: 0.2476803167140913\n",
      "ArgId F1: 0.23614059919792404\n",
      "full-structure Precision: 0.304536068740425\n",
      "full-structure Recall: 0.3235210868949901\n",
      "full-structure F1: 0.3137416366443644\n",
      "-----processing time: 0hour:6min:10sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-10/49/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-10/29/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-10/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-25/24/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-25/24/\n",
      "/disk/data/models/framenet/proto_distilling-25/24/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 24\n",
      "SenseId Accuracy: 0.5226603884638023\n",
      "ArgId Precision: 0.3060709327275022\n",
      "ArgId Recall: 0.30001237164419153\n",
      "ArgId F1: 0.303011370735974\n",
      "full-structure Precision: 0.3955911539552027\n",
      "full-structure Recall: 0.394919332012454\n",
      "full-structure F1: 0.3952549575070821\n",
      "-----processing time: 0hour:5min:54sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\t###eval for mulModel (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/dict_framenet/mulModel-25/48/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa82841f6d743c69a85ff0e94f3d32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a319d8c0567f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/disk/data/models/eval_result_test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n\u001b[0;32m---> 14\u001b[0;31m      model_path=model_path, result_dir=result_dir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-4bbd38f6f728>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(srl, masking, viterbi, language, model_path, result_dir, train_lang, tgt, pretrained)\u001b[0m\n\u001b[1;32m     65\u001b[0m         model = parser.ShallowSemanticParser(srl=srl,gold_pred=True, model_path=m, viterbi=viterbi, \n\u001b[1;32m     66\u001b[0m                                              \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multilingual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                              pretrained=pretrained)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mgold_senses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_senses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/parser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fnversion, language, masking, srl, model_path, gold_pred, viterbi, tgt, pretrained)\u001b[0m\n\u001b[1;32m     84\u001b[0m                                                                    \u001b[0mnum_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbio_arg2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                                                    \u001b[0mlufrmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlufrmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                                                    frargmap = self.bert_io.bio_frargmap)\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...loaded model path:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             )\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Load config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pruned_heads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-25/24/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "# print('\\t###eval for mulModel (no masking)')\n",
    "# model_path = '/disk/data/models/dict_framenet/mulModel-25/48/'\n",
    "# result_dir = '/disk/data/models/eval_result_test'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for mulModel (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-25/48/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-25/48/\n",
      "/disk/data/models/framenet/mulModel-25/48/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 48\n",
      "SenseId Accuracy: 0.5126545026486168\n",
      "ArgId Precision: 0.3024447949526814\n",
      "ArgId Recall: 0.2846715328467153\n",
      "ArgId F1: 0.29328914664457334\n",
      "full-structure Precision: 0.39299781181619253\n",
      "full-structure Recall: 0.38126238324370226\n",
      "full-structure F1: 0.38704116083614676\n",
      "-----processing time: 0hour:6min:3sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for mulModel (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-25/48/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-10/19/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-10/19/\n",
      "/disk/data/models/framenet/proto_distilling-10/19/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.4226015303119482\n",
      "ArgId Precision: 0.24136287824636646\n",
      "ArgId Recall: 0.2506495113200544\n",
      "ArgId F1: 0.24591855313467254\n",
      "full-structure Precision: 0.31208307544185404\n",
      "full-structure Recall: 0.3211151995471271\n",
      "full-structure F1: 0.316534719073693\n",
      "-----processing time: 0hour:6min:10sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/proto_distilling_for_ko_result.txt\n",
      "\t###eval for mulModel (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/dict_framenet/mulModel-10/42/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308e9790b77144dd9a3efba41731ea34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bb37d5546623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/disk/data/models/eval_result_test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n\u001b[0;32m---> 14\u001b[0;31m      model_path=model_path, result_dir=result_dir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-4bbd38f6f728>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(srl, masking, viterbi, language, model_path, result_dir, train_lang, tgt, pretrained)\u001b[0m\n\u001b[1;32m     65\u001b[0m         model = parser.ShallowSemanticParser(srl=srl,gold_pred=True, model_path=m, viterbi=viterbi, \n\u001b[1;32m     66\u001b[0m                                              \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multilingual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                              pretrained=pretrained)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mgold_senses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_senses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/parser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fnversion, language, masking, srl, model_path, gold_pred, viterbi, tgt, pretrained)\u001b[0m\n\u001b[1;32m     84\u001b[0m                                                                    \u001b[0mnum_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbio_arg2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                                                    \u001b[0mlufrmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlufrmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                                                    frargmap = self.bert_io.bio_frargmap)\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...loaded model path:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             )\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Load config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pruned_heads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-10/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "# print('\\t###eval for mulModel (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/mulModel-10/42/'\n",
    "# result_dir = '/disk/data/models/eval_result_test'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for mulModel (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-10/42/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-10/42/\n",
      "/disk/data/models/framenet/mulModel-10/42/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 42\n",
      "SenseId Accuracy: 0.4220129487934079\n",
      "ArgId Precision: 0.24556174679279513\n",
      "ArgId Recall: 0.23444265742917234\n",
      "ArgId F1: 0.23987341772151902\n",
      "full-structure Precision: 0.3161992646528729\n",
      "full-structure Recall: 0.3103594678743278\n",
      "full-structure F1: 0.31325215155519054\n",
      "-----processing time: 0hour:6min:3sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\t###eval for mulModel (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-10/42/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-10/24/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for mulModel (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/dict_framenet/mulModel-100/19/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/dict_framenet/mulModel-100/19/\n",
      "/disk/data/models/dict_framenet/mulModel-100/19/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.6860898567784972\n",
      "ArgId Precision: 0.4223639154563703\n",
      "ArgId Recall: 0.44253371273042186\n",
      "ArgId F1: 0.4322136297728371\n",
      "full-structure Precision: 0.5307105027856112\n",
      "full-structure Recall: 0.5459949051797339\n",
      "full-structure F1: 0.5382442188971435\n",
      "-----processing time: 0hour:5min:54sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "\n",
    "# print('\\t###eval for proto-distill (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling-10/37/'\n",
    "# result_dir = '/disk/data/models/eval_result_test'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for mulModel (no masking)')\n",
    "model_path = '/disk/data/models/dict_framenet/mulModel-100/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for ko (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/koModel/39/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/koModel/39/\n",
      "/disk/data/models/framenet/koModel/39/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 39\n",
      "SenseId Accuracy: 0.6996272317049245\n",
      "ArgId Precision: 0.41950934579439253\n",
      "ArgId Recall: 0.4442657429172337\n",
      "ArgId F1: 0.43153277654269057\n",
      "full-structure Precision: 0.532510905125409\n",
      "full-structure Recall: 0.5528587602604019\n",
      "full-structure F1: 0.5424940980419387\n",
      "-----processing time: 0hour:5min:48sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for ko (no masking)')\n",
    "model_path = '/disk/data/models/framenet/koModel/39/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t###eval for ko (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-100/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for ko (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/koModel/33/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/koModel/33/\n",
      "/disk/data/models/framenet/koModel/33/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 33\n",
      "SenseId Accuracy: 0.694526191877575\n",
      "ArgId Precision: 0.42381848107218434\n",
      "ArgId Recall: 0.44599777310404554\n",
      "ArgId F1: 0.4346253541503406\n",
      "full-structure Precision: 0.5331691971002599\n",
      "full-structure Recall: 0.5516558165864704\n",
      "full-structure F1: 0.542254990610002\n",
      "-----processing time: 0hour:5min:48sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for ko (no masking)')\n",
    "model_path = '/disk/data/models/framenet/koModel/33/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for mulModel (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet_old/mulModel-100/19/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet_old/mulModel-100/19/\n",
      "/disk/data/models/framenet_old/mulModel-100/19/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.42377869334902885\n",
      "ArgId Precision: 0.3293627159023228\n",
      "ArgId Recall: 0.3420759618953359\n",
      "ArgId F1: 0.3355989804587936\n",
      "full-structure Precision: 0.3707810320781032\n",
      "full-structure Recall: 0.3762383243702236\n",
      "full-structure F1: 0.37348974431019955\n",
      "-----processing time: 0hour:6min:13sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for mulModel (no masking)')\n",
    "model_path = '/disk/data/models/framenet_old/mulModel-100/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto_distilling (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling_alpha02/35/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling_alpha02/35/\n",
      "/disk/data/models/framenet/proto_distilling_alpha02/35/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 35\n",
      "SenseId Accuracy: 0.672160094173043\n",
      "ArgId Precision: 0.41789646287186694\n",
      "ArgId Recall: 0.4414202647531857\n",
      "ArgId F1: 0.4293363816858191\n",
      "full-structure Precision: 0.5207663359562094\n",
      "full-structure Recall: 0.5385649589583923\n",
      "full-structure F1: 0.5295161234215744\n",
      "-----processing time: 0hour:6min:12sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "print('\\t###eval for proto_distilling (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling_alpha02/35/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "\n",
    "print('\\t###eval for proto-distill (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-25/19/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for mulModel (no masking)')\n",
    "model_path = '/disk/data/models/framenet/proto_distilling-25/48/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for ko (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/ko_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: ko\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/koModel/33/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/koModel/33/\n",
      "/disk/data/models/framenet/koModel/33/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 33\n",
      "SenseId Accuracy: 0.694526191877575\n",
      "ArgId Precision: 0.42381848107218434\n",
      "ArgId Recall: 0.44599777310404554\n",
      "ArgId F1: 0.4346253541503406\n",
      "full-structure Precision: 0.5331691971002599\n",
      "full-structure Recall: 0.5516558165864704\n",
      "full-structure F1: 0.542254990610002\n",
      "-----processing time: 0hour:6min:6sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/ko_for_ko_result.txt\n",
      "\t###eval for mulModel (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-100/45/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-100/45/\n",
      "/disk/data/models/framenet/mulModel-100/45/\n",
      "...model is loaded\n",
      "# EPOCH: 45\n",
      "SenseId Accuracy: 0.6843241122228761\n",
      "ArgId Precision: 0.4303104077906269\n",
      "ArgId Recall: 0.4373376221699864\n",
      "ArgId F1: 0.4337955577371456\n",
      "full-structure Precision: 0.535819430814524\n",
      "full-structure Recall: 0.5409000849136711\n",
      "full-structure F1: 0.5383477709697867\n",
      "-----processing time: 0hour:6min:10sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result_test/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "\n",
    "print('\\t###eval for ko (no masking)')\n",
    "model_path = '/disk/data/models/framenet/koModel/33/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for mulModel (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-100/45/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "\n",
    "print('\\t###eval for ko (no masking)')\n",
    "model_path = '/disk/data/models/framenet/koModel-25/33/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n",
    "     model_path=model_path, result_dir=result_dir)\n",
    "\n",
    "print('\\t###eval for mulModel (no masking)')\n",
    "model_path = '/disk/data/models/framenet/mulModel-25/48/'\n",
    "result_dir = '/disk/data/models/eval_result_test'\n",
    "test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = 'framenet'\n",
    "language = 'ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###eval for ko Model (masking)')\n",
    "# model_path = '/disk/data/models/framenet/koModel-25/'\n",
    "# result_dir = '/disk/data/models/eval_result-25'\n",
    "\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###eval for proto-distill (masking)')\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling-25/'\n",
    "# result_dir = '/disk/data/models/eval_result-25'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko (masking)')\n",
    "# model_path = '/disk/data/models/framenet/mulModel-25/'\n",
    "# result_dir = '/disk/data/models/eval_result-25'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###eval for ko Model (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/koModel-25/'\n",
    "# result_dir = '/disk/data/models/eval_result-25'\n",
    "\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-25/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-25/36/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-25/36/\n",
      "/disk/data/models/framenet/proto_distilling-25/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 36\n",
      "SenseId Accuracy: 0.5175593486364528\n",
      "ArgId Precision: 0.2794674624124871\n",
      "ArgId Recall: 0.3012495360633428\n",
      "ArgId F1: 0.28994998809240297\n",
      "full-structure Precision: 0.37441624365482234\n",
      "full-structure Recall: 0.3914520237758279\n",
      "full-structure F1: 0.38274466392223333\n",
      "-----processing time: 0hour:19min:57sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-25/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###eval for proto-distill (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling-25/'\n",
    "# result_dir = '/disk/data/models/eval_result-25'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###multilingual-for-ko (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-25/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-25/36/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-25/36/\n",
      "/disk/data/models/framenet/mulModel-25/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 36\n",
      "SenseId Accuracy: 0.5057877182656465\n",
      "ArgId Precision: 0.28733614232209737\n",
      "ArgId Recall: 0.30372386490164544\n",
      "ArgId F1: 0.2953028207132976\n",
      "full-structure Precision: 0.3748550378606999\n",
      "full-structure Recall: 0.3888338522502123\n",
      "full-structure F1: 0.3817165086311694\n",
      "-----processing time: 0hour:20min:6sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-25/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###multilingual-for-ko (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/mulModel-25/'\n",
    "# result_dir = '/disk/data/models/eval_result-25'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for 100 (ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = 'framenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# print('\\t###eval for ko Model (masking)')\n",
    "# model_path = '/disk/data/models/framenet/koModel/'\n",
    "# result_dir = '/disk/data/models/eval_result-100'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-100/proto_distilling_for_ko_with_masking_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: True\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling/35/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling/35/\n",
      "/disk/data/models/framenet/proto_distilling/35/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 35\n",
      "SenseId Accuracy: 0.8193054738081225\n",
      "ArgId Precision: 0.44407425035697284\n",
      "ArgId Recall: 0.4617097612272671\n",
      "ArgId F1: 0.45272032510462784\n",
      "full-structure Precision: 0.5997507960681158\n",
      "full-structure Recall: 0.6130767053495613\n",
      "full-structure F1: 0.6063405416754146\n",
      "-----processing time: 0hour:20min:19sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-100/proto_distilling_for_ko_with_masking_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###eval for proto-distill (masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling/'\n",
    "# result_dir = '/disk/data/models/eval_result-100'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###multilingual-for-ko (masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-100/mul_for_ko_with_masking_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: True\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/dict_framenet/mulModel-100/35/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/dict_framenet/mulModel-100/35/\n",
      "/disk/data/models/dict_framenet/mulModel-100/35/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 35\n",
      "SenseId Accuracy: 0.8147930154993133\n",
      "ArgId Precision: 0.4389241249706366\n",
      "ArgId Recall: 0.46232834343684276\n",
      "ArgId F1: 0.4503223474121829\n",
      "full-structure Precision: 0.5928845626542364\n",
      "full-structure Recall: 0.6120152844607982\n",
      "full-structure F1: 0.6022980501392757\n",
      "-----processing time: 0hour:20min:23sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-100/mul_for_ko_with_masking_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###multilingual-for-ko (masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/dict_framenet/mulModel-100/'\n",
    "# result_dir = '/disk/data/models/eval_result-100'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for ko Model (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-100/ko_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: ko\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/koModel/36/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/koModel/36/\n",
      "/disk/data/models/framenet/koModel/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 36\n",
      "SenseId Accuracy: 0.6960957425936826\n",
      "ArgId Precision: 0.4214622641509434\n",
      "ArgId Recall: 0.44216256340467647\n",
      "ArgId F1: 0.43156433013343\n",
      "full-structure Precision: 0.5331867527827402\n",
      "full-structure Recall: 0.5491084064534391\n",
      "full-structure F1: 0.5410304678240258\n",
      "-----processing time: 0hour:20min:24sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-100/ko_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###eval for ko Model (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/koModel/'\n",
    "# result_dir = '/disk/data/models/eval_result-100'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-100/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling/36/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling/36/\n",
      "/disk/data/models/framenet/proto_distilling/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 36\n",
      "SenseId Accuracy: 0.6680400235432608\n",
      "ArgId Precision: 0.42099447513812155\n",
      "ArgId Recall: 0.4242236793269826\n",
      "ArgId F1: 0.4226029085531181\n",
      "full-structure Precision: 0.5234852208102225\n",
      "full-structure Recall: 0.5275969431078403\n",
      "full-structure F1: 0.5255330396475771\n",
      "-----processing time: 0hour:20min:22sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-100/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###eval for proto-distill (no masking)')\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling/'\n",
    "# result_dir = '/disk/data/models/eval_result-100'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###multilingual-for-ko (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-100/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-100/36/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-100/36/\n",
      "/disk/data/models/framenet/mulModel-100/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 36\n",
      "SenseId Accuracy: 0.6807926231116342\n",
      "ArgId Precision: 0.42610866722149565\n",
      "ArgId Recall: 0.4433997278238278\n",
      "ArgId F1: 0.43458227234145747\n",
      "full-structure Precision: 0.5309734513274337\n",
      "full-structure Recall: 0.5434474950467025\n",
      "full-structure F1: 0.5371380612673101\n",
      "-----processing time: 0hour:20min:25sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-100/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###multilingual-for-ko (no masking)')\n",
    "# # model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "# result_dir = '/disk/data/models/eval_result-100'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval for 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###eval for ko Model (masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/koModel-10/'\n",
    "# result_dir = '/disk/data/models/eval_result-10'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###eval for proto-distill (masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling-10/'\n",
    "# result_dir = '/disk/data/models/eval_result-10'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###multilingual-for-ko (masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-10/mul_for_ko_with_masking_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: True\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-10/35/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-10/35/\n",
      "/disk/data/models/framenet/mulModel-10/35/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-8f18b34a3443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/disk/data/models/eval_result-10'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n\u001b[0;32m----> 6\u001b[0;31m      model_path=model_path, result_dir=result_dir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-e021eef19859>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(srl, masking, viterbi, language, model_path, result_dir, train_lang, tgt, pretrained)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#             try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mgold_sense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/parser.py\u001b[0m in \u001b[0;36mparser\u001b[0;34m(self, input_d, sent_id, result_format)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                                token_type_ids=b_token_type_ids, attention_mask=b_masks)\n\u001b[1;32m    132\u001b[0m                     sense_logits, arg_logits = self.model(b_input_ids, lus=b_lus, \n\u001b[0;32m--> 133\u001b[0;31m                                                           token_type_ids=b_token_type_ids, attention_mask=b_masks)\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'framenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/src/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, lus, senses, args, using_gold_fame, position_ids, head_mask)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0marg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mlufr_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlufrmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_senses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0msense_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# loss for sense id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/src/utils.py\u001b[0m in \u001b[0;36mget_masks\u001b[0;34m(datas, mapdata, num_label, masking)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;31m#                 torch.cuda.set_device(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mindx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;31m#                 mask = [3e-5 for i in range(num_label)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;31m#                 mask = torch.tensor(mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print('\\t###multilingual-for-ko (masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-10/'\n",
    "# result_dir = '/disk/data/models/eval_result-10'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###eval for ko Model (no masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/koModel-10/'\n",
    "# result_dir = '/disk/data/models/eval_result-10'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###eval for proto-distill (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-10/proto_distilling_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: proto_distilling\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/proto_distilling-10/36/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/proto_distilling-10/36/\n",
      "/disk/data/models/framenet/proto_distilling-10/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 36\n",
      "SenseId Accuracy: 0.4251520502256229\n",
      "ArgId Precision: 0.2394453386158227\n",
      "ArgId Recall: 0.23926759866386244\n",
      "ArgId F1: 0.23935643564356437\n",
      "full-structure Precision: 0.31554327025303\n",
      "full-structure Recall: 0.31502971978488536\n",
      "full-structure F1: 0.3152862858963918\n",
      "-----processing time: 0hour:20min:8sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-10/proto_distilling_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###eval for proto-distill (no masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling-10/'\n",
    "# result_dir = '/disk/data/models/eval_result-10'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='proto_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###multilingual-for-ko (no masking)\n",
      "### Your result would be saved to: /disk/data/models/eval_result-10/mul_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: mul\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet/mulModel-10/36/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet/mulModel-10/36/\n",
      "/disk/data/models/framenet/mulModel-10/36/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:309: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 36\n",
      "SenseId Accuracy: 0.42475966254659603\n",
      "ArgId Precision: 0.23360254527655408\n",
      "ArgId Recall: 0.23617468761598417\n",
      "ArgId F1: 0.23488157490003075\n",
      "full-structure Precision: 0.30922710725287034\n",
      "full-structure Recall: 0.31255307104443814\n",
      "full-structure F1: 0.3108811936936937\n",
      "-----processing time: 0hour:20min:12sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/data/models/eval_result-10/mul_for_ko_result.txt\n"
     ]
    }
   ],
   "source": [
    "# print('\\t###multilingual-for-ko (no masking)')\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-10/'\n",
    "# result_dir = '/disk/data/models/eval_result-10'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for proto-distill (ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###eval for proto-distill (masking)')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling/'\n",
    "\n",
    "# result_dir = '/disk/data/models/proto_distilling/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='prot-_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-no-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/eval_result/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('\\t###eval for proto-distill (masking)')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/proto_distilling/'\n",
    "\n",
    "# result_dir = '/disk/data/models/proto_distilling/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='prot-_distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for en for en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/enModel-with-exemplar/'\n",
    "\n",
    "# result_dir = '/disk/data/models/eval_result/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for ko for ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/enModel-with-exemplar/'\n",
    "\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/koModel/'\n",
    "# result_dir = '/disk/data/models/results/framenet/koModel/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/enModel-with-exemplar/'\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###ko-for-ko-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/koModel/'\n",
    "# result_dir = '/disk/data/models/results/framenet/koModel/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###en-for-ko-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = ''\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###en-for-ko-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = ''\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for KFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/eval_result/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/results/framenet/mulModel-100/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for En again using mulModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/eval_result/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/results/framenet/mulModel-100-for-en/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for distilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/distilling/'\n",
    "\n",
    "# result_dir = '/disk/data/models/distilling/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='distilling', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
