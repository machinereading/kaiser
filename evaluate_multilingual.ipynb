{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n",
      "\n",
      "\t###DEVICE: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import parser\n",
    "from src import dataio\n",
    "import glob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "with open('./data/frame_coreFE_list.json','r') as f:\n",
    "    frame_coreFE = json.load(f)\n",
    "\n",
    "def weighting(frame, args):\n",
    "    weighted_args = []\n",
    "    for arg in args:\n",
    "        weighted_args.append(arg)\n",
    "        if arg in frame_coreFE[frame]:\n",
    "            weighted_args.append(arg)\n",
    "        else:\n",
    "            pass\n",
    "    return weighted_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(srl=False, masking=False, viterbi=False, language=False, model_path=False, \n",
    "         result_dir=False, train_lang=False, tgt=False, \n",
    "         pretrained=\"bert-base-multilingual-cased\"):\n",
    "    if not result_dir:\n",
    "        result_dir = '/disk/data/models/'+model_dir.split('/')[-2]+'-result/'\n",
    "    else:\n",
    "        pass\n",
    "    if result_dir[-1] != '/':\n",
    "        result_dir = result_dir+'/'\n",
    "        \n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "        \n",
    "    if not train_lang:\n",
    "        train_lang = language\n",
    "    \n",
    "    fname = fname = result_dir+train_lang+'_for_'+language\n",
    "        \n",
    "    if masking:\n",
    "        fname = fname + '_with_masking_result.txt'\n",
    "    else:\n",
    "        fname = fname +'_result.txt'\n",
    "        \n",
    "    print('### Your result would be saved to:', fname)\n",
    "        \n",
    "    trn, dev, tst = dataio.load_data(srl=srl, language=language, exem=False)\n",
    "    print('### EVALUATION')\n",
    "    print('MODE:', srl)\n",
    "    print('target LANGUAGE:', language)\n",
    "    print('trained LANGUAGE:', train_lang)\n",
    "    print('Viterbi:', viterbi)\n",
    "    print('masking:', masking)\n",
    "    print('using TGT token:', tgt)\n",
    "    tic()    \n",
    "        \n",
    "    models = glob.glob(model_path+'*/')\n",
    "    \n",
    "#     models = []\n",
    "    \n",
    "    # en_exemplar best\n",
    "#     models.append('/disk/data/models/dict_framenet/enModel-with-exemplar/9/')\n",
    "#     models.append('/disk/data/models/frameBERT/frameBERT_en/')\n",
    "    \n",
    "#     # ko best\n",
    "#     models.append('/disk/data/models/framenet/koModel/35/')\n",
    "    \n",
    "    # mul best\n",
    "#     models.append('/disk/data/models/framenet_old/mulModel-100/39/')\n",
    "#     models.append('/disk/data/models/dict_framenet/mulModel-100/39/')\n",
    "    \n",
    "    eval_result = []\n",
    "    for m in models:\n",
    "#         m = '/disk/data/models/framenet/enModel-with-exemplar/epoch-8-joint.pt'\n",
    "        print('### model dir:', m)\n",
    "        print('### TARGET LANGUAGE:', language)\n",
    "        torch.cuda.set_device(device)\n",
    "        model = parser.ShallowSemanticParser(srl=srl,gold_pred=True, model_path=m, viterbi=viterbi, \n",
    "                                             masking=masking, language='multilingual', tgt=tgt,\n",
    "                                             pretrained=pretrained)\n",
    "\n",
    "        gold_senses, pred_senses, gold_args, pred_args = [],[],[],[]        \n",
    "        gold_full_all, pred_full_all = [],[]\n",
    "\n",
    "        for instance in tst:\n",
    "            torch.cuda.set_device(device)\n",
    "#             try:\n",
    "            result = model.parser(instance)\n",
    "\n",
    "            gold_sense = [i for i in instance[2] if i != '_'][0]\n",
    "            pred_sense = [i for i in result[0][2] if i != '_'][0]\n",
    "\n",
    "\n",
    "            gold_arg = [i for i in instance[3] if i != 'X']\n",
    "            pred_arg = [i for i in result[0][3]]\n",
    "\n",
    "            gold_senses.append(gold_sense)\n",
    "            pred_senses.append(pred_sense)\n",
    "\n",
    "            gold_args.append(gold_arg)\n",
    "            pred_args.append(pred_arg)\n",
    "\n",
    "            if srl == 'framenet':\n",
    "                gold_full = []\n",
    "                gold_full.append(gold_sense)\n",
    "                gold_full.append(gold_sense)\n",
    "                weighted_gold_args = weighting(gold_sense, gold_arg)\n",
    "                gold_full += weighted_gold_args\n",
    "\n",
    "                pred_full = []\n",
    "                pred_full.append(pred_sense)\n",
    "                pred_full.append(pred_sense)\n",
    "                weighted_pred_args = weighting(pred_sense, pred_arg)\n",
    "                pred_full += weighted_pred_args\n",
    "\n",
    "                gold_full_all.append(gold_full)\n",
    "                pred_full_all.append(pred_full)\n",
    "                \n",
    "                    \n",
    "#             except KeyboardInterrupt:\n",
    "#                 raise\n",
    "#             except:\n",
    "#                 print(\"cuda error\")\n",
    "#                 pass\n",
    "            \n",
    "#             break\n",
    "            \n",
    "        acc = accuracy_score(gold_senses, pred_senses)\n",
    "        arg_f1 = f1_score(gold_args, pred_args)\n",
    "        arg_precision = precision_score(gold_args, pred_args)\n",
    "        arg_recall = recall_score(gold_args, pred_args)\n",
    "        \n",
    "\n",
    "#         epoch = m.split('/')[-1].split('-')[1]\n",
    "        epoch = m.split('/')[-2]\n",
    "        print('# EPOCH:', epoch)\n",
    "        print(\"SenseId Accuracy: {}\".format(acc))\n",
    "        print(\"ArgId Precision: {}\".format(arg_precision))\n",
    "        print(\"ArgId Recall: {}\".format(arg_recall))\n",
    "        print(\"ArgId F1: {}\".format(arg_f1))\n",
    "        if srl == 'framenet':\n",
    "            full_f1 = f1_score(gold_full_all, pred_full_all)\n",
    "            full_precision = precision_score(gold_full_all, pred_full_all)\n",
    "            full_recall = recall_score(gold_full_all, pred_full_all)\n",
    "            print(\"full-structure Precision: {}\".format(full_precision))\n",
    "            print(\"full-structure Recall: {}\".format(full_recall))\n",
    "            print(\"full-structure F1: {}\".format(full_f1))\n",
    "        print('-----processing time:', tac())\n",
    "        print('')\n",
    "\n",
    "\n",
    "        model_result = []\n",
    "        model_result.append(epoch)\n",
    "        model_result.append(acc)\n",
    "        model_result.append(arg_precision)\n",
    "        model_result.append(arg_recall)\n",
    "        model_result.append(arg_f1)\n",
    "        if srl == 'framenet':\n",
    "            model_result.append(full_precision)\n",
    "            model_result.append(full_recall)\n",
    "            model_result.append(full_f1)\n",
    "        model_result = [str(i) for i in model_result]\n",
    "        eval_result.append(model_result)\n",
    "            \n",
    "#         break\n",
    "        \n",
    "#     print(eval_result)\n",
    "    \n",
    "    \n",
    "    with open(fname,'w') as f:\n",
    "        if srl == 'framenet':\n",
    "            f.write('epoch'+'\\t''SenseID'+'\\t'+'Arg_P'+'\\t'+'Arg_R'+'\\t'+'ArgF1'+'\\t'+'full_P'+'\\t'+'full_R'+'\\t'+'full_F1'+'\\n')\n",
    "        else:\n",
    "            f.write('epoch'+'\\t''SenseID'+'\\t'+'Arg_P'+'\\t'+'Arg_R'+'\\t'+'ArgF1'+'\\n')\n",
    "        for i in eval_result:\n",
    "            line = '\\t'.join(i)\n",
    "            f.write(line+'\\n')\n",
    "            \n",
    "        print('\\n\\t### Your result is saved at:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for en for en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/enModel-with-exemplar/'\n",
    "\n",
    "# result_dir = '/disk/data/models/eval_result/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for ko for ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/enModel-with-exemplar/'\n",
    "\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/koModel/'\n",
    "# result_dir = '/disk/data/models/results/framenet/koModel/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###multilingual-for-en-without-masking\n",
      "### Your result would be saved to: /disk/data/models/results/framenet/enModel-with-exemplar/en_with_exem_for_en_result.txt\n",
      "# of instances in trn: 19391\n",
      "# of instances in dev: 2272\n",
      "# of instances in tst: 6714\n",
      "data example: [['Greece', 'wildfires', 'force', 'thousands', 'to', '<tgt>', 'evacuate', '</tgt>'], ['_', '_', '_', '_', '_', '_', 'evacuate.v', '_'], ['_', '_', '_', '_', '_', '_', 'Escaping', '_'], ['O', 'O', 'O', 'B-Escapee', 'O', 'X', 'O', 'X']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: en\n",
      "trained LANGUAGE: en_with_exem\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/framenet_old/mulModel-100/39/\n",
      "### TARGET LANGUAGE: en\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/framenet_old/mulModel-100/39/\n",
      "/disk/data/models/framenet_old/mulModel-100/39/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:284: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendric_unit Calendric_unit\n",
      "Likelihood Likelihood\n",
      "Giving Revenge\n",
      "Awareness Awareness\n",
      "Increment Increment\n",
      "Purpose Statement\n",
      "Goal Goal\n",
      "Grasp Grasp\n",
      "Giving Revenge\n",
      "Assistance Assistance\n",
      "Causation Means\n",
      "People People\n",
      "Desiring Desiring\n",
      "Awareness Awareness\n",
      "Degree Revenge\n",
      "Importance Revenge\n",
      "Frequency Frequency\n",
      "People People\n",
      "Needing Needing\n",
      "Being_employed Work\n",
      "Familiarity Awareness\n",
      "Importance Importance\n",
      "Causation Causation\n",
      "Giving Giving\n",
      "Goal Locative_relation\n",
      "Motion Motion\n",
      "Temporal_collocation Temporal_collocation\n",
      "Capability Capability\n",
      "Emotion_directed Emotion_directed\n",
      "Commerce_buy Commerce_buy\n",
      "Temporal_collocation Temporal_collocation\n",
      "Capability Capability\n",
      "Commerce_buy Commerce_buy\n",
      "Money Earnings_and_losses\n",
      "Being_employed Work\n",
      "Earnings_and_losses Earnings_and_losses\n",
      "Money Commerce_scenario\n",
      "Possession Possession\n",
      "Text_creation Text_creation\n",
      "Being_named Being_named\n",
      "Capability Capability\n",
      "Emotion_directed Experiencer_focus\n",
      "Locative_relation Locative_relation\n",
      "Being_employed Work\n",
      "Cause_change Undergo_change\n",
      "Causation Causation\n",
      "Goal Goal\n",
      "Personal_relationship Personal_relationship\n",
      "Arriving Arriving\n",
      "First_experience Ordinal_numbers\n",
      "Temporal_collocation Temporal_collocation\n",
      "Kinship Kinship\n",
      "Quantified_mass Suspicion\n",
      "Documents Revenge\n",
      "Degree Degree\n",
      "Goal Goal\n",
      "Ordinal_numbers Ordinal_numbers\n",
      "Intentionally_act Intentionally_act\n",
      "Becoming Becoming\n",
      "Arriving Arriving\n",
      "Degree Degree\n",
      "Temporal_collocation Economy\n",
      "Experiencer_focus Experiencer_focus\n",
      "Being_employed Being_employed\n",
      "People People\n",
      "Desiring Desiring\n",
      "Causation Causation\n",
      "Frequency Communication_manner\n",
      "Activity_finish Activity_finish\n",
      "Precipitation Precipitation\n",
      "Precipitation Precipitation\n",
      "Vehicle Vehicle\n",
      "Goal Manipulate_into_shape\n",
      "Kinship Kinship\n",
      "Operate_vehicle Operate_vehicle\n",
      "Likelihood Willingness\n",
      "Cause_change Cause_change\n",
      "Awareness Awareness\n",
      "Possession Possession\n",
      "Expertise Expertise\n",
      "Quantified_mass Suspicion\n",
      "Sole_instance Commerce_scenario\n",
      "Expertise Expertise\n",
      "Opportunity Alternatives\n",
      "Cause_change Cause_change\n",
      "Ordinal_numbers Ordinal_numbers\n",
      "Possession Possession\n",
      "Desiring Desiring\n",
      "Locative_relation Locative_relation\n",
      "Ingestion Ingestion\n",
      "Ranked_expectation Capacity\n",
      "Hunting Terrorism\n",
      "People People\n",
      "Education_teaching Terrorism\n",
      "Cause_to_continue Cause_to_continue\n",
      "Being_obligated Attempt\n",
      "Arriving Arriving\n",
      "Time_vector Time_vector\n",
      "Goal Goal\n",
      "Being_employed Being_employed\n",
      "Desiring Desiring\n",
      "Being_employed Being_employed\n",
      "Desiring Desiring\n",
      "Travel Travel\n",
      "Temporal_collocation Temporal_collocation\n",
      "Being_employed Being_employed\n",
      "Possession Possession\n",
      "Possession Possession\n",
      "Possession Possession\n",
      "Similarity Similarity\n",
      "Increment Increment\n",
      "Possession Terrorism\n",
      "Judgment Judgment\n",
      "Intentionally_affect Intentionally_act\n",
      "Performers_and_roles Performers_and_roles\n",
      "Performers_and_roles Performers_and_roles\n",
      "Calendric_unit Calendric_unit\n",
      "Assistance Assistance\n",
      "Quantified_mass Quantity\n",
      "Partitive Measure_mass\n",
      "People People\n",
      "Confronting_problem Body_parts\n",
      "Desiring Desiring\n",
      "Being_employed Work\n",
      "Cardinal_numbers Cardinal_numbers\n",
      "Purpose Purpose\n",
      "Supply Supply\n",
      "Being_employed Being_employed\n",
      "Economy Economy\n",
      "Assistance Assistance\n",
      "Opportunity Alternatives\n",
      "Candidness Candidness\n",
      "Being_employed Work\n",
      "People People\n",
      "Confronting_problem Confronting_problem\n",
      "People_by_age Terrorism\n",
      "Predicament Predicament\n",
      "Sufficiency Revenge\n",
      "Cause_to_amalgamate Revenge\n",
      "Contingency Reason\n",
      "Possession Possession\n",
      "Being_employed Being_employed\n",
      "Expertise Expertise\n",
      "Resolve_problem Resolve_problem\n",
      "Type Type\n",
      "Supply Supply\n",
      "Public_services Terrorism\n",
      "People People\n",
      "Assistance Assistance\n",
      "Calendric_unit Calendric_unit\n",
      "Assistance Assistance\n",
      "Locating Locating\n",
      "Cause_change_of_position_on_a_scale Emphasizing\n",
      "People People\n",
      "Being_employed Being_employed\n",
      "Relative_time Relative_time\n",
      "Giving Giving\n",
      "Being_employed Being_employed\n",
      "Public_services Terrorism\n",
      "Assistance Assistance\n",
      "Supporting Supporting\n",
      "People People\n",
      "Partitive Quantity\n",
      "Quantified_mass Quantity\n",
      "Existence Existence\n",
      "Supporting Operating_a_system\n",
      "Feeling Feeling\n",
      "Awareness Awareness\n",
      "Temporal_collocation Temporal_collocation\n",
      "Assistance Assistance\n",
      "Capability Capability\n",
      "Awareness Candidness\n",
      "Being_employed Being_employed\n",
      "Assistance Assistance\n",
      "People People\n",
      "Locating Locating\n",
      "Assistance Assistance\n",
      "Calendric_unit Temporal_collocation\n",
      "Giving Giving\n",
      "Using Come_into_effect\n",
      "Giving Giving\n",
      "Stinginess Revenge\n",
      "Leadership Relational_political_locales\n",
      "Calendric_unit Calendric_unit\n",
      "Giving Revenge\n",
      "Taking_time Taking_time\n",
      "Building_subparts Architectural_part\n",
      "Taking_time Locative_relation\n",
      "Buildings Terrorism\n",
      "Education_teaching Terrorism\n",
      "Cardinal_numbers Measure_mass\n",
      "Proportional_quantity Relational_quantity\n",
      "Measure_duration Measure_duration\n",
      "Time_vector Time_vector\n",
      "Duration_description Duration_description\n",
      "Being_employed Being_employed\n",
      "Assistance Assistance\n",
      "Intentionally_act Intentionally_act\n",
      "Cardinal_numbers Measure_mass\n",
      "Being_employed Being_employed\n",
      "Purpose Purpose\n",
      "Request Request\n",
      "Taking_time Capacity\n",
      "Quantified_mass Come_into_effect\n",
      "Frugality Revenge\n",
      "Undergo_change Undergo_change\n",
      "Needing Needing\n",
      "People People_by_religion\n",
      "Public_services Public_services\n",
      "Activity_ongoing Activity_ongoing\n",
      "Similarity Revenge\n",
      "Personal_relationship Personal_relationship\n",
      "Assistance Assistance\n",
      "Accompaniment Accompaniment\n",
      "Assistance Assistance\n",
      "Aggregate Aggregate\n",
      "Frugality Ground_up\n",
      "Temporal_collocation Relative_time\n",
      "Frugality Revenge\n",
      "Money Earnings_and_losses\n",
      "Being_employed Being_employed\n",
      "Activity_ongoing Assistance\n",
      "People People\n",
      "Request Request\n",
      "Locating Locating\n",
      "Activity_prepare Activity_prepare\n",
      "Giving Revenge\n",
      "Using Come_into_effect\n",
      "Activity_ongoing Activity_ongoing\n",
      "Assistance Assistance\n",
      "Partitive Partitive\n",
      "Cardinal_numbers Measure_mass\n",
      "Morality_evaluation Aesthetics\n",
      "People People_by_religion\n",
      "Political_locales Political_locales\n",
      "Usefulness Desirability\n",
      "Labeling Topic\n",
      "Cardinal_numbers Cardinal_numbers\n",
      "Calendric_unit Temporal_subregion\n",
      "Medium Measure_area\n",
      "Usefulness Usefulness\n",
      "Usefulness Usefulness\n",
      "Text Text\n",
      "Statement Statement\n",
      "Increment Increment\n",
      "Usefulness Usefulness\n",
      "Regard Judgment\n",
      "Dimension Assessing\n",
      "Supporting Subjective_influence\n",
      "Partitive Measure_mass\n",
      "Temporal_collocation Concessive\n",
      "Predicament Predicament\n",
      "Objective_influence Objective_influence\n",
      "Aggregate Terrorism\n",
      "Increment Increment\n",
      "Change_position_on_a_scale Change_position_on_a_scale\n",
      "Aggregate Aggregate\n",
      "Being_employed Unemployment_rate\n",
      "Assistance Assistance\n",
      "Sole_instance Capacity\n",
      "Objective_influence Objective_influence\n",
      "Emanating Revenge\n",
      "Employing Terrorism\n",
      "Becoming_aware Locating\n",
      "Businesses Terrorism\n",
      "Reliance Objective_influence\n",
      "Kinship Kinship\n",
      "Performers_and_roles Intentionally_act\n",
      "Performers_and_roles Representing\n",
      "Public_services Terrorism\n",
      "Assistance Assistance\n",
      "Coincidence Event\n",
      "Predicament Predicament\n",
      "Difficulty Difficulty\n",
      "Awareness Awareness\n",
      "Statement Speak_on_topic\n",
      "Membership Come_into_effect\n",
      "Earnings_and_losses Earnings_and_losses\n",
      "Supporting Revenge\n",
      "Money Earnings_and_losses\n",
      "Calendric_unit Calendric_unit\n",
      "Employing Employing\n",
      "Causation Causation\n",
      "Perception_experience Grasp\n",
      "Type People_by_religion\n",
      "Subjective_influence Revenge\n",
      "Public_services Terrorism\n",
      "Creating Possession\n",
      "Being_employed Work\n",
      "Employing Terrorism\n",
      "Kinship Kinship\n",
      "Statement Statement\n",
      "Possibility Revenge\n",
      "Difficulty Difficulty\n",
      "Possibility Capability\n",
      "Awareness Awareness\n",
      "Intentionally_act Measure_area\n",
      "Possibility Capability\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2a13fbf7e64d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/disk/data/models/results/framenet/enModel-with-exemplar/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_with_exem', \n\u001b[0;32m----> 7\u001b[0;31m      model_path=model_path, result_dir=result_dir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-7291472bbd79>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(srl, masking, viterbi, language, model_path, result_dir, train_lang, tgt, pretrained)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#             try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mgold_sense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/parser.py\u001b[0m in \u001b[0;36mparser\u001b[0;34m(self, input_d, sent_id, result_format)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                                token_type_ids=b_token_type_ids, attention_mask=b_masks)\n\u001b[1;32m    132\u001b[0m                     sense_logits, arg_logits = self.model(b_input_ids, lus=b_lus, \n\u001b[0;32m--> 133\u001b[0;31m                                                           token_type_ids=b_token_type_ids, attention_mask=b_masks)\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'framenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/src/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, lus, senses, args, using_gold_fame, position_ids, head_mask)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0marg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mlufr_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlufrmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_senses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#         sense_loss = 0 # loss for sense id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print('\\t###multilingual-for-en-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/enModel-with-exemplar/'\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t###ko-for-ko-without-masking\n",
      "### Your result would be saved to: /disk/data/models/results/framenet/koModel/ko_for_ko_result.txt\n",
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n",
      "# of instances in trn: 17838\n",
      "# of instances in dev: 2548\n",
      "# of instances in tst: 5097\n",
      "data example: [['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '<tgt>', '순이익이', '</tgt>', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'X', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "### EVALUATION\n",
      "MODE: framenet\n",
      "target LANGUAGE: ko\n",
      "trained LANGUAGE: ko\n",
      "Viterbi: False\n",
      "masking: False\n",
      "using TGT token: True\n",
      "### model dir: /disk/data/models/dict_framenet/mulModel-100/39/\n",
      "### TARGET LANGUAGE: ko\n",
      "srl model: framenet\n",
      "language: multilingual\n",
      "version: 1.1\n",
      "using viterbi: False\n",
      "using masking: False\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lu2idx.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_lufrmap.json\n",
      "\t /disk/kaiser/kaiser/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/data/models/dict_framenet/mulModel-100/39/\n",
      "/disk/data/models/dict_framenet/mulModel-100/39/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kaiser/src/utils.py:284: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Businesses Businesses\n",
      "Calendric_unit Calendric_unit\n",
      "Objective_influence Objective_influence\n",
      "Calendric_unit Separating\n",
      "Measure_duration Measure_duration\n",
      "Change_position_on_a_scale Change_position_on_a_scale\n",
      "Earnings_and_losses Change_position_on_a_scale\n",
      "Earnings_and_losses Contingency\n",
      "Commerce_sell Commerce_sell\n",
      "Craft Artifact\n",
      "Fluidic_motion Fluidic_motion\n",
      "Locale_by_use Locale_by_use\n",
      "Partitive Partitive\n",
      "Evoking Arriving\n",
      "People_by_jurisdiction Education_teaching\n",
      "Chatting Social_interaction_evaluation\n",
      "Connecting_architecture Connecting_architecture\n",
      "First_experience Ordinal_numbers\n",
      "Building_subparts Building_subparts\n",
      "Noise_makers Noise_makers\n",
      "History History\n",
      "Noise_makers Noise_makers\n",
      "People_by_origin People_by_origin\n",
      "Noise_makers Type\n",
      "Measure_mass Measure_mass\n",
      "Cause_to_make_noise Cause_to_make_noise\n",
      "Building_subparts Building_subparts\n",
      "Statement Statement\n",
      "Noise_makers Noise_makers\n",
      "Locative_relation Locative_relation\n",
      "Artifact Containers\n",
      "Process_end Process_end\n",
      "Noise_makers Noise_makers\n",
      "Using Using\n",
      "Change_event_time Change_event_time\n",
      "Part_orientational Architectural_part\n",
      "Cause_to_make_noise Cause_to_make_noise\n",
      "Activity_finish Activity_finish\n",
      "Attempt_suasion Attempt_suasion\n",
      "Cause_to_make_noise Cause_to_make_noise\n",
      "Becoming Emotion_directed\n",
      "Partitive Partitive\n",
      "Residence Residence\n",
      "Have_as_requirement Being_obligated\n",
      "Project Project\n",
      "Change_position_on_a_scale Progression\n",
      "Sign Certainty\n",
      "Intentionally_create Intentionally_create\n",
      "Economy Economy\n",
      "Capability Capability\n",
      "Usefulness Desirability\n",
      "Possession Possession\n",
      "Wealthiness Frugality\n",
      "Agree_or_refuse_to_act Agree_or_refuse_to_act\n",
      "Speed_description Money\n",
      "Activity_resume Activity_resume\n",
      "Change_of_leadership Change_of_leadership\n",
      "Creating Position_on_a_scale\n",
      "Cause_change_of_position_on_a_scale Cause_change_of_position_on_a_scale\n",
      "Stimulus_focus Experiencer_focus\n",
      "Moving_in_place Moving_in_place\n",
      "Calendric_unit Calendric_unit\n",
      "Time_vector Time_vector\n",
      "Self_motion Motion\n",
      "Locative_relation Locative_relation\n",
      "Partitive Partitive\n",
      "Arriving Coming_to_be\n",
      "Measure_duration Measure_duration\n",
      "Moving_in_place Moving_in_place\n",
      "Locative_relation Architectural_part\n",
      "Architectural_part Architectural_part\n",
      "Measure_duration Calendric_unit\n",
      "Cogitation Cogitation\n",
      "Motion_directional Cause_motion\n",
      "Moving_in_place Moving_in_place\n",
      "Vehicle Vehicle\n",
      "Locative_relation Locative_relation\n",
      "Boundary Having_or_lacking_access\n",
      "Moving_in_place Moving_in_place\n",
      "Locative_relation Experiencer_focus\n",
      "Quantity Quantity\n",
      "Locative_relation Locative_relation\n",
      "Time_vector Time_vector\n",
      "Substance Substance\n",
      "Desirability Stimulus_focus\n",
      "Awareness Cogitation\n",
      "Body_parts Body_parts\n",
      "Kinship Kinship\n",
      "Locative_relation Part_orientational\n",
      "Difficulty Level_of_force_exertion\n",
      "Coming_to_believe Becoming_aware\n",
      "Connecting_architecture Connecting_architecture\n",
      "Measure_duration Measure_duration\n",
      "Predicament Predicament\n",
      "Locative_relation Chatting\n",
      "Self_motion Self_motion\n",
      "Text Text\n",
      "Buildings Buildings\n",
      "Departing Departing\n",
      "Taking_time Taking_time\n",
      "Body_parts Body_parts\n",
      "Sign Change_position_on_a_scale\n",
      "Text_creation Using\n",
      "Education_teaching Education_teaching\n",
      "People_by_vocation Opinion\n",
      "Expertise Capability\n",
      "People Military\n",
      "Kinship People_by_age\n",
      "Sufficiency Sufficiency\n",
      "Hostile_encounter Hostile_encounter\n",
      "Expertise Likelihood\n",
      "Capability Capability\n",
      "Linguistic_meaning Medical_professionals\n",
      "People_by_vocation People\n",
      "Locative_relation Locative_relation\n",
      "Locale_by_use Locale_by_use\n",
      "Locative_relation Locative_relation\n",
      "Time_vector Time_vector\n",
      "Education_teaching Education_teaching\n",
      "Attempt Attempt\n",
      "Existence Existence\n",
      "Removing Ceasing_to_be\n",
      "Kinship Kinship\n",
      "Locale_by_use Locale_by_use\n",
      "Intentionally_act Intentionally_act\n",
      "Possession Activity_prepare\n",
      "Political_locales Political_locales\n",
      "Morality_evaluation Morality_evaluation\n",
      "Education_teaching Education_teaching\n",
      "Filling Filling\n",
      "Simple_name Communicate_categorization\n",
      "Education_teaching Education_teaching\n",
      "Expertise Expertise\n",
      "Possession Bringing\n",
      "Calendric_unit Calendric_unit\n",
      "Choosing Choosing\n",
      "Calendric_unit Calendric_unit\n",
      "Causation Successful_action\n",
      "Statement Statement\n",
      "Opinion Certainty\n",
      "Membership Leadership\n",
      "Have_associated Getting\n",
      "Leadership Leadership\n",
      "Membership Membership\n",
      "Becoming Becoming\n",
      "Bringing Goal\n",
      "Beat_opponent Beat_opponent\n",
      "Temporal_collocation Ordinal_numbers\n",
      "Intentionally_create Intentionally_create\n",
      "Emphasizing Emphasizing\n",
      "Beat_opponent Beat_opponent\n",
      "Body_parts Attributed_information\n",
      "Reason Reason\n",
      "Supply Supply\n",
      "Origin Origin\n",
      "Leadership Leadership\n",
      "Political_locales Law\n",
      "Removing Removing\n",
      "Intentionally_create Deciding\n",
      "Intentionally_act Intentionally_act\n",
      "Evidence Evidence\n",
      "Aggregate Calendric_unit\n",
      "Scrutiny Scrutiny\n",
      "Political_locales Political_locales\n",
      "Leadership Leadership\n",
      "Encoding Explaining_the_facts\n",
      "Scrutiny Scrutiny\n",
      "Part_whole Relational_quantity\n",
      "Explaining_the_facts Explaining_the_facts\n",
      "Conduct Intentionally_act\n",
      "Political_locales Political_locales\n",
      "Locale_by_use Locale_by_use\n",
      "Goal Locative_relation\n",
      "Awareness Awareness\n",
      "Desiring Desiring\n",
      "Importance Relational_quantity\n",
      "Intentionally_act Ordinal_numbers\n",
      "Quantity Quantity\n",
      "Relative_time Relative_time\n",
      "Awareness Awareness\n",
      "Quantity Quantity\n",
      "Locative_relation Distributed_position\n",
      "Being_employed Being_employed\n",
      "Stimulus_focus Accomplishment\n",
      "Alternatives Project\n",
      "Giving Giving\n",
      "Stinginess Relative_time\n",
      "Money Money\n",
      "Diversity Means\n",
      "People People\n",
      "Activity_ongoing Activity_ongoing\n",
      "Relative_time Relative_time\n",
      "Becoming_aware Becoming_aware\n",
      "Predicament Predicament\n",
      "Activity_start Activity_start\n",
      "Being_employed Being_employed\n",
      "Supporting Supporting\n",
      "People People\n",
      "People People\n",
      "Causation Successful_action\n",
      "Work Being_employed\n",
      "People People\n",
      "Possession Giving\n",
      "Assistance Assistance\n",
      "Relative_time Temporal_collocation\n",
      "Giving Giving\n",
      "Impact Motion\n",
      "Temporal_collocation Temporal_collocation\n",
      "Unemployment_rate Being_employed\n",
      "Possession Possession\n",
      "Partitive Partitive\n",
      "People People\n",
      "Activity_ongoing Activity_ongoing\n",
      "Supply Offering\n",
      "Hostile_encounter Cause_change_of_strength\n",
      "People_by_age People_by_age\n",
      "Existence Existence\n",
      "Temporal_collocation Temporal_collocation\n",
      "Temporal_collocation Temporal_collocation\n",
      "Temporal_collocation Temporal_collocation\n",
      "Abusing Abusing\n",
      "Difficulty Difficulty\n",
      "Quantity Quantity\n",
      "Desirability Desirability\n",
      "Cogitation Opinion\n",
      "Statement Statement\n",
      "Text_creation Text_creation\n",
      "Desirability Locale\n",
      "Intentionally_create Intentionally_create\n",
      "Locale Locale\n",
      "Locale Locale\n",
      "Evidence Linguistic_meaning\n",
      "Change_position_on_a_scale Motion\n",
      "Causation Causation\n",
      "Obviousness Obviousness\n",
      "Dominate_situation Leadership\n",
      "Residence Dead_or_alive\n",
      "Capability Capability\n",
      "Vehicle Vehicle\n",
      "Arriving Arriving\n",
      "Undergo_change Undergo_change\n",
      "Coming_to_be Intentionally_create\n",
      "Distinctiveness Idiosyncrasy\n",
      "Duplication Remainder\n",
      "Instance Becoming_aware\n",
      "Work Work\n",
      "Temporal_subregion Temporal_subregion\n",
      "Import_export_scenario Importing\n",
      "Progression Progression\n",
      "Buildings Buildings\n",
      "Supply Supply\n",
      "Locale Locale\n",
      "Type Indigenous_origin\n",
      "Craft Text\n",
      "Locale Locale\n",
      "Exchange Exchange\n",
      "Roadways Buildings\n",
      "Process_continue Process_continue\n",
      "Origin Origin\n",
      "Judgment Existence\n",
      "Temporal_collocation Temporal_collocation\n",
      "Natural_features Natural_features\n",
      "Building Building\n",
      "Leadership Military\n",
      "Destroying Destroying\n",
      "Natural_features Natural_features\n",
      "Being_named Awareness\n",
      "Temporal_collocation Temporal_collocation\n",
      "Leadership Military\n",
      "Importance Importance\n",
      "Causation Bringing\n",
      "Origin Origin\n",
      "Locative_relation Locative_relation\n",
      "People People\n",
      "Political_locales Political_locales\n",
      "People_by_religion People_by_religion\n",
      "Differentiation Similarity\n",
      "Natural_features Natural_features\n",
      "Natural_features Natural_features\n",
      "Quantity Self_motion\n",
      "Political_locales Political_locales\n",
      "Cause_motion Attack\n",
      "People_by_religion People_by_religion\n",
      "Direction Direction\n",
      "Military Leadership\n",
      "Temporal_subregion Calendric_unit\n",
      "Objective_influence Objective_influence\n",
      "Concessive Concessive\n",
      "Origin Origin\n",
      "Origin Origin\n",
      "Natural_features Natural_features\n",
      "Political_locales Political_locales\n",
      "Text_creation Text_creation\n",
      "Successful_action Successful_action\n",
      "Measure_duration Calendric_unit\n",
      "Natural_features Natural_features\n",
      "People People\n",
      "Political_locales Political_locales\n",
      "Distributed_position Inhibit_movement\n",
      "Stage_of_progress Temporal_collocation\n",
      "Attempt Attempt\n",
      "Inclusion Inclusion\n",
      "Military Military\n",
      "Natural_features Natural_features\n",
      "Origin Origin\n",
      "Hostile_encounter Hostile_encounter\n",
      "Activity_start Process_start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel Touring\n",
      "Becoming Becoming\n",
      "Becoming_a_member Becoming_a_member\n",
      "Membership Membership\n",
      "Infrastructure Locale_by_use\n",
      "Dimension Dimension\n",
      "Statement Statement\n",
      "Roadways Experiencer_focus\n",
      "Political_locales Relational_political_locales\n",
      "Architectural_part Architectural_part\n",
      "Political_locales Political_locales\n",
      "Building Building\n",
      "People Commerce_buy\n",
      "Buildings Buildings\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-47b858513d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/disk/data/models/results/framenet/koModel/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n\u001b[0;32m----> 7\u001b[0;31m      model_path=model_path, result_dir=result_dir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-69532b9eebfe>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(srl, masking, viterbi, language, model_path, result_dir, train_lang, tgt, pretrained)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m#             try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mgold_sense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/parser.py\u001b[0m in \u001b[0;36mparser\u001b[0;34m(self, input_d, sent_id, result_format)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     tmp_eval_loss = self.model(b_input_ids, lus=b_lus, \n\u001b[0;32m--> 131\u001b[0;31m                                                token_type_ids=b_token_type_ids, attention_mask=b_masks)\n\u001b[0m\u001b[1;32m    132\u001b[0m                     sense_logits, arg_logits = self.model(b_input_ids, lus=b_lus, \n\u001b[1;32m    133\u001b[0m                                                           token_type_ids=b_token_type_ids, attention_mask=b_masks)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk/kaiser/kaiser/src/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, lus, senses, args, using_gold_fame, position_ids, head_mask)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    736\u001b[0m                                        \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                                        \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                                        encoder_attention_mask=encoder_extended_attention_mask)\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print('\\t###ko-for-ko-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/koModel/'\n",
    "# result_dir = '/disk/data/models/results/framenet/koModel/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###en-for-ko-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = ''\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###en-for-ko-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = ''\n",
    "# result_dir = '/disk/data/models/results/framenet/enModel-with-exemplar/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_with_exem', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for KFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/eval_result/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-ko-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'ko'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/results/framenet/mulModel-100/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for En again using mulModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/eval_result/'\n",
    "# test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='mul', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\t###multilingual-for-en-without-masking')\n",
    "# srl = 'framenet'\n",
    "# language = 'en'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "# model_path = '/disk/data/models/framenet/mulModel-100/'\n",
    "\n",
    "# result_dir = '/disk/data/models/results/framenet/mulModel-100-for-en/'\n",
    "# test(srl=srl, language=language, masking=False, viterbi=False, tgt=True, train_lang='en_ko', \n",
    "#      model_path=model_path, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval for distilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t###multilingual-for-ko-masking')\n",
    "srl = 'framenet'\n",
    "language = 'ko'\n",
    "model_path = '/disk/data/models/framenet/distilling/'\n",
    "\n",
    "result_dir = '/disk/data/models/distilling/'\n",
    "test(srl=srl, language=language, masking=True, viterbi=False, tgt=True, train_lang='distilling', \n",
    "     model_path=model_path, result_dir=result_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
