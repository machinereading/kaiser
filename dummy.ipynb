{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1117 17:15:44.863185 140388328597248 file_utils.py:39] PyTorch version 0.4.1 available.\n",
      "I1117 17:15:45.022875 140388328597248 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import *\n",
    "from kaiser.src import utils\n",
    "from kaiser.src import dataio\n",
    "from kaiser import target_identifier\n",
    "from kaiser import inference\n",
    "from kaiser.src.modeling import BertForJointShallowSemanticParsing\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '안녕 나는 <tgt> 사랑해 </tgt>'\n",
    "\n",
    "bert_io = utils.for_BERT(mode='predict')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['안녕', '나는', '<tgt>', '사랑해', '</tgt>'], ['[CLS]', '안', '##녕', '나는', '<tgt>', '사', '##랑', '##해', '</tgt>', '[SEP]'], [1, 3, 4, 5, 8])\n",
      "[101, 9521, 118741, 100585, 1, 9405, 62200, 14523, 2, 102]\n"
     ]
    }
   ],
   "source": [
    "t = bert_io.bert_tokenizer(text)\n",
    "print(t)\n",
    "print(bert_io.tokenizer.convert_tokens_to_ids(t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1117 17:26:04.724481 140388328597248 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/hahmyg/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
      "I1117 17:26:04.728356 140388328597248 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I1117 17:26:05.823536 140388328597248 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/hahmyg/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "input_ids = torch.tensor(bert_io.tokenizer.convert_tokens_to_ids(t[1])).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.0073e-01, -1.4202e-01,  3.8447e-01,  ...,  6.1753e-01,\n",
      "          -1.3053e-01,  3.0373e-01],\n",
      "         [ 1.7382e-01, -4.1211e-01,  3.5874e-01,  ...,  1.1530e+00,\n",
      "           9.4785e-02,  1.2455e-01],\n",
      "         [ 2.9706e-01, -4.0844e-01,  7.3426e-01,  ...,  8.9539e-01,\n",
      "          -1.1355e-01,  1.9625e-01],\n",
      "         ...,\n",
      "         [ 5.0557e-01,  1.1449e-01,  5.6316e-01,  ...,  7.3965e-01,\n",
      "          -4.5839e-01,  6.3396e-01],\n",
      "         [ 6.6071e-01, -2.9220e-01,  7.8144e-01,  ...,  6.6861e-01,\n",
      "          -6.5892e-01,  5.4593e-01],\n",
      "         [ 5.3778e-01, -3.0699e-01,  8.5603e-01,  ...,  7.9521e-01,\n",
      "          -2.0699e-01,  3.8107e-01]]], grad_fn=<AddcmulBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
